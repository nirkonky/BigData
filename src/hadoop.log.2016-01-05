2016-01-05 03:59:50,726 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 03:59:50,745 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 03:59:50,999 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 03:59:51,005 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 03:59:51,177 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 03:59:51,185 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 03:59:51,197 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training2025205346/.staging/job_local2025205346_0001
2016-01-05 03:59:51,198 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/training/Desktop/outputa
2016-01-05 04:00:56,355 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 04:00:56,365 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 04:00:56,634 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:00:56,640 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:00:56,700 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:00:56,715 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:00:56,752 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training2127632207/.staging/job_local2127632207_0001
2016-01-05 04:00:56,753 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/training/Desktop/outputa
2016-01-05 04:01:52,859 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 04:01:52,882 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 04:01:53,098 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:01:53,102 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:01:53,157 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:01:53,191 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:01:53,204 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training40367094/.staging/job_local40367094_0001
2016-01-05 04:01:53,207 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory /home/training/Desktop/output already exists
2016-01-05 04:02:03,222 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 04:02:03,233 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 04:02:03,434 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:02:03,435 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:02:03,495 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:02:03,510 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:02:03,526 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training505400981/.staging/job_local505400981_0001
2016-01-05 04:02:03,528 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory /home/training/Desktop/output already exists
2016-01-05 04:02:28,284 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 04:02:28,295 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 04:02:28,542 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:02:28,543 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:02:28,655 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:02:28,684 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:02:28,691 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training61542885/.staging/job_local61542885_0001
2016-01-05 04:02:28,691 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory /home/training/Desktop/output already exists
2016-01-05 04:02:52,933 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 04:02:52,947 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 04:02:53,238 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:02:53,241 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:02:53,307 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:02:53,328 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:02:53,349 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training91151340/.staging/job_local91151340_0001
2016-01-05 04:02:53,350 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory /home/training/Desktop/output already exists
2016-01-05 04:03:31,393 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 04:03:31,404 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 04:03:31,625 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:03:31,627 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:03:31,705 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:03:31,732 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:03:31,795 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training499445065/.staging/job_local499445065_0001
2016-01-05 04:03:31,795 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory /home/training/Desktop/output already exists
2016-01-05 04:04:19,435 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 04:04:19,454 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 04:04:19,712 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:04:19,718 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:04:19,787 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:04:19,804 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:04:19,819 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training1349015384/.staging/job_local1349015384_0001
2016-01-05 04:04:19,827 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory /home/training/Desktop/output already exists
2016-01-05 04:04:55,032 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 04:04:55,040 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 04:04:55,301 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:04:55,302 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:04:55,400 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:04:55,432 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:04:55,452 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training729471392/.staging/job_local729471392_0001
2016-01-05 04:04:55,452 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory /home/training/Desktop/output already exists
2016-01-05 04:07:34,563 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:07:34,568 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:07:34,730 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:07:34,753 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:07:34,807 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 2
2016-01-05 04:07:35,670 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local291390866_0001
2016-01-05 04:07:35,671 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 04:07:35,695 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 04:07:35,769 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 04:07:35,771 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local291390866_0001_m_000000_0
2016-01-05 04:07:35,807 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:07:35,917 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 04:07:35,956 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@62c3e9e9
2016-01-05 04:07:35,960 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors:0+102
2016-01-05 04:07:35,969 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:07:35,974 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:07:36,455 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:07:36,455 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:07:36,562 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:07:36,563 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 04:07:36,679 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 04:07:36,743 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 04:07:36,749 INFO org.apache.hadoop.mapred.Task: Task:attempt_local291390866_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 04:07:36,811 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:07:36,811 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local291390866_0001_m_000000_0' done.
2016-01-05 04:07:36,811 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local291390866_0001_m_000000_0
2016-01-05 04:07:36,811 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local291390866_0001_m_000001_0
2016-01-05 04:07:36,811 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:07:36,813 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5e29c58e
2016-01-05 04:07:36,814 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors~:0+0
2016-01-05 04:07:36,814 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:07:36,814 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:07:36,925 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:07:36,925 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:07:36,928 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:07:36,930 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 04:07:36,937 INFO org.apache.hadoop.mapred.Task: Task:attempt_local291390866_0001_m_000001_0 is done. And is in the process of commiting
2016-01-05 04:07:36,938 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:07:36,938 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local291390866_0001_m_000001_0' done.
2016-01-05 04:07:36,939 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local291390866_0001_m_000001_0
2016-01-05 04:07:36,939 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 04:07:36,955 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:07:36,965 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5a199939
2016-01-05 04:07:36,965 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:07:36,990 INFO org.apache.hadoop.mapred.Merger: Merging 2 sorted segments
2016-01-05 04:07:37,164 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 314 bytes
2016-01-05 04:07:37,164 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:07:37,229 INFO org.apache.hadoop.mapred.Task: Task:attempt_local291390866_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 04:07:37,230 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:07:37,230 INFO org.apache.hadoop.mapred.Task: Task attempt_local291390866_0001_r_000000_0 is allowed to commit now
2016-01-05 04:07:37,232 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local291390866_0001_r_000000_0' to /home/training/Desktop/Canopy/output
2016-01-05 04:07:37,232 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 04:07:37,232 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local291390866_0001_r_000000_0' done.
2016-01-05 04:07:37,681 INFO org.apache.hadoop.mapred.JobClient:  map 50% reduce 100%
2016-01-05 04:07:37,682 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local291390866_0001
2016-01-05 04:07:37,754 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 04:07:37,754 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 04:07:37,754 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2034
2016-01-05 04:07:37,754 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=266372
2016-01-05 04:07:37,754 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 04:07:37,754 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 04:07:37,755 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 04:07:37,755 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 04:07:37,755 INFO org.apache.hadoop.mapred.JobClient:     Map input records=21
2016-01-05 04:07:37,755 INFO org.apache.hadoop.mapred.JobClient:     Map output records=12
2016-01-05 04:07:37,755 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=288
2016-01-05 04:07:37,755 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=239
2016-01-05 04:07:37,755 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 04:07:37,755 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 04:07:37,756 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=10
2016-01-05 04:07:37,756 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 04:07:37,756 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=12
2016-01-05 04:07:37,756 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=10
2016-01-05 04:07:37,756 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=24
2016-01-05 04:07:37,756 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 04:07:37,757 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 04:07:37,757 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 04:07:37,757 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=481112064
2016-01-05 04:08:42,854 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:08:42,865 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:08:43,155 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:08:43,170 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:08:43,194 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training1422562475/.staging/job_local1422562475_0001
2016-01-05 04:08:43,195 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory /home/training/Desktop/Canopy/output already exists
2016-01-05 04:12:37,604 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 04:12:37,614 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 04:12:37,873 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:12:37,874 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:12:37,961 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:12:38,000 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:12:38,058 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training86346037/.staging/job_local86346037_0001
2016-01-05 04:12:38,059 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/training/Desktop/output
2016-01-05 04:13:35,176 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 04:13:35,203 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 04:13:35,504 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:13:35,506 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:13:35,593 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:13:35,619 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:13:35,671 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 04:13:36,377 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local137277192_0001
2016-01-05 04:13:36,379 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 04:13:36,402 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 04:13:36,537 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 04:13:36,538 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local137277192_0001_m_000000_0
2016-01-05 04:13:36,612 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:13:36,723 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 04:13:36,757 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@27b03c1a
2016-01-05 04:13:36,760 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors:0+530
2016-01-05 04:13:36,805 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:13:36,812 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:13:37,247 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:13:37,250 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:13:37,402 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 04:13:37,508 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 04:13:37,545 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 04:13:37,602 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:13:37,602 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 04:13:38,152 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 04:13:38,154 INFO org.apache.hadoop.mapred.Task: Task:attempt_local137277192_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 04:13:38,332 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:13:38,332 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local137277192_0001_m_000000_0' done.
2016-01-05 04:13:38,332 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local137277192_0001_m_000000_0
2016-01-05 04:13:38,333 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 04:13:38,364 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:13:38,371 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@6691177
2016-01-05 04:13:38,371 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:13:38,410 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 0%
2016-01-05 04:13:38,418 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 04:13:38,638 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 04:13:38,638 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:13:39,091 INFO org.apache.hadoop.mapred.Task: Task:attempt_local137277192_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 04:13:39,092 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:13:39,092 INFO org.apache.hadoop.mapred.Task: Task attempt_local137277192_0001_r_000000_0 is allowed to commit now
2016-01-05 04:13:39,096 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local137277192_0001_r_000000_0' to /home/training/Desktop/output
2016-01-05 04:13:39,100 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 04:13:39,100 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local137277192_0001_r_000000_0' done.
2016-01-05 04:13:39,410 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 04:13:39,411 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local137277192_0001
2016-01-05 04:13:39,791 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 04:13:39,792 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 04:13:39,792 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2256
2016-01-05 04:13:39,792 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181600
2016-01-05 04:13:39,792 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 04:13:39,793 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 04:13:39,793 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 04:13:39,793 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 04:13:39,793 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 04:13:39,793 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 04:13:39,793 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 04:13:39,794 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 04:13:39,794 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 04:13:39,794 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 04:13:39,794 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 04:13:39,794 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 04:13:39,795 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 04:13:39,796 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 04:13:39,796 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 04:13:39,796 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 04:13:39,796 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 04:13:39,796 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 04:13:39,796 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 04:13:39,797 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 04:13:39,797 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 04:13:39,992 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 04:13:40,129 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:13:40,131 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:13:40,132 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training1039106858/.staging/job_local1039106858_0002
2016-01-05 04:13:40,132 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/training/Desktop/output1
2016-01-05 04:19:55,945 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 04:19:55,951 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 04:19:55,965 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 04:19:56,249 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:19:56,257 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:19:56,534 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:19:56,540 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:19:56,555 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 04:19:57,179 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 04:19:57,185 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local224712665_0001
2016-01-05 04:19:57,207 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 04:19:57,317 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 04:19:57,318 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local224712665_0001_m_000000_0
2016-01-05 04:19:57,366 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:19:57,519 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 04:19:57,554 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@2339e351
2016-01-05 04:19:57,559 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors:0+530
2016-01-05 04:19:57,612 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:19:57,618 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:19:58,022 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:19:58,022 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:19:58,200 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 04:19:58,280 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 04:19:58,302 WARN org.apache.hadoop.fs.FSInputChecker: Problem opening checksum file: file:/home/training/Desktop/Canopy/output/part-r-00000.  Ignoring exception: 
java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:147)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:334)
	at org.apache.hadoop.io.SequenceFile$Reader.openFile(SequenceFile.java:1787)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1707)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at Kmeans.KMeansMapper.setup(KMeansMapper.java:32)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:138)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:19:58,399 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 04:19:58,400 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local224712665_0001
java.lang.Exception: java.io.EOFException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at Kmeans.KMeansMapper.setup(KMeansMapper.java:32)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:138)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:19:59,202 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local224712665_0001
2016-01-05 04:19:59,204 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 04:19:59,217 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 04:25:54,348 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:25:54,352 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:25:54,645 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:25:54,673 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:25:54,706 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 04:25:55,311 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1488074752_0001
2016-01-05 04:25:55,313 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 04:25:55,326 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 04:25:55,423 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 04:25:55,428 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1488074752_0001_m_000000_0
2016-01-05 04:25:55,509 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:25:55,647 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 04:25:55,704 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@4816ef71
2016-01-05 04:25:55,711 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors:0+530
2016-01-05 04:25:55,747 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:25:55,764 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:25:56,235 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:25:56,236 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:25:56,326 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 04:25:56,821 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 04:25:56,854 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 04:25:56,914 WARN org.apache.hadoop.fs.FSInputChecker: Problem opening checksum file: file:/home/training/Desktop/Canopy/output/part-r-00000.  Ignoring exception: 
java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:147)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:334)
	at org.apache.hadoop.io.SequenceFile$Reader.openFile(SequenceFile.java:1787)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1707)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at Kmeans.KMeansMapper.setup(KMeansMapper.java:32)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:138)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:25:57,033 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 04:25:57,034 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1488074752_0001
java.lang.Exception: java.io.EOFException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at Kmeans.KMeansMapper.setup(KMeansMapper.java:32)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:138)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:25:57,327 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1488074752_0001
2016-01-05 04:25:57,474 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 04:25:57,516 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 04:32:42,102 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:32:42,105 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:32:42,453 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:32:42,484 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:32:42,541 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 2
2016-01-05 04:32:43,407 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local769010155_0001
2016-01-05 04:32:43,408 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 04:32:43,418 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 04:32:43,568 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 04:32:43,569 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local769010155_0001_m_000000_0
2016-01-05 04:32:43,602 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:32:43,649 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 04:32:43,672 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@583a5794
2016-01-05 04:32:43,680 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors:0+530
2016-01-05 04:32:43,694 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:32:43,711 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:32:43,854 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:32:43,855 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:32:43,898 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local769010155_0001_m_000001_0
2016-01-05 04:32:43,898 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:32:43,903 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@d18d189
2016-01-05 04:32:43,905 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors~:0+0
2016-01-05 04:32:43,908 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:32:43,909 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:32:44,103 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 04:32:44,108 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local769010155_0001
java.lang.Exception: java.lang.NumberFormatException: For input string: "SEQVector.ClusterCenter"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: java.lang.NumberFormatException: For input string: "SEQVector.ClusterCenter"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1222)
	at java.lang.Double.valueOf(Double.java:475)
	at java.lang.Double.<init>(Double.java:567)
	at Canopy.CanopyMapper.map(CanopyMapper.java:35)
	at Canopy.CanopyMapper.map(CanopyMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:32:44,416 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 04:32:44,417 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local769010155_0001
2016-01-05 04:32:44,418 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 04:33:41,683 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:33:41,704 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:33:41,952 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:33:41,996 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:33:42,039 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 2
2016-01-05 04:33:42,731 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1787347526_0001
2016-01-05 04:33:42,732 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 04:33:42,743 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 04:33:42,797 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 04:33:42,798 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1787347526_0001_m_000000_0
2016-01-05 04:33:42,843 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:33:42,910 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 04:33:42,914 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@583a5794
2016-01-05 04:33:42,919 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors:0+530
2016-01-05 04:33:42,929 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:33:42,931 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:33:43,039 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:33:43,040 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:33:43,050 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1787347526_0001_m_000001_0
2016-01-05 04:33:43,050 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:33:43,051 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@427eb6e2
2016-01-05 04:33:43,052 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors~:0+0
2016-01-05 04:33:43,053 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:33:43,053 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:33:43,177 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 04:33:43,187 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1787347526_0001
java.lang.Exception: java.lang.NumberFormatException: For input string: "SEQVector.ClusterCenter"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: java.lang.NumberFormatException: For input string: "SEQVector.ClusterCenter"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1222)
	at java.lang.Double.valueOf(Double.java:475)
	at java.lang.Double.<init>(Double.java:567)
	at Canopy.CanopyMapper.map(CanopyMapper.java:35)
	at Canopy.CanopyMapper.map(CanopyMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:33:43,737 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 04:33:43,738 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1787347526_0001
2016-01-05 04:33:43,739 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 04:34:08,414 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:34:08,421 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:34:08,631 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:34:08,651 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:34:08,704 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 2
2016-01-05 04:34:09,436 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1984807645_0001
2016-01-05 04:34:09,438 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 04:34:09,457 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 04:34:09,539 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 04:34:09,539 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1984807645_0001_m_000000_0
2016-01-05 04:34:09,607 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:34:09,661 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 04:34:09,665 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@59c208b0
2016-01-05 04:34:09,669 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors:0+530
2016-01-05 04:34:09,679 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:34:09,683 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:34:09,816 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:34:09,819 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:34:09,852 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1984807645_0001_m_000001_0
2016-01-05 04:34:09,852 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:34:09,857 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@2e1551b0
2016-01-05 04:34:09,863 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors~:0+0
2016-01-05 04:34:09,863 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:34:09,864 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:34:10,156 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 04:34:10,160 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1984807645_0001
java.lang.Exception: java.lang.NumberFormatException: For input string: "SEQVector.ClusterCenter"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: java.lang.NumberFormatException: For input string: "SEQVector.ClusterCenter"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1222)
	at java.lang.Double.valueOf(Double.java:475)
	at java.lang.Double.<init>(Double.java:567)
	at Canopy.CanopyMapper.map(CanopyMapper.java:35)
	at Canopy.CanopyMapper.map(CanopyMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:34:10,447 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 04:34:10,448 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1984807645_0001
2016-01-05 04:34:10,450 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 04:36:27,384 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:36:27,399 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:36:27,548 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:36:27,565 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:36:27,578 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training1050347776/.staging/job_local1050347776_0001
2016-01-05 04:36:27,583 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory /home/training/Desktop/Canopy/output already exists
2016-01-05 04:37:11,404 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:37:11,411 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:37:11,572 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:37:11,603 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:37:11,646 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 2
2016-01-05 04:37:12,737 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local2084314112_0001
2016-01-05 04:37:12,738 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 04:37:12,750 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 04:37:12,810 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 04:37:12,812 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2084314112_0001_m_000000_0
2016-01-05 04:37:12,880 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:37:12,932 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 04:37:12,999 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@6cf1f051
2016-01-05 04:37:13,003 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors:0+44
2016-01-05 04:37:13,012 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:37:13,015 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:37:13,206 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:37:13,207 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:37:13,234 INFO org.apache.hadoop.fs.FSInputChecker: Found checksum error: b[0, 44]=312c340a332c350a362c350a372c340a332c340a352c370a362c340a322c330a342c350a362c340a332c340a
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Canopy/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:225)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:147)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:484)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:76)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:85)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:139)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:37:13,239 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2084314112_0001_m_000001_0
2016-01-05 04:37:13,239 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:37:13,244 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@18330bf
2016-01-05 04:37:13,246 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors~:0+0
2016-01-05 04:37:13,246 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:37:13,247 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:37:13,600 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 04:37:13,603 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local2084314112_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Canopy/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Canopy/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:225)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:147)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:484)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:76)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:85)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:139)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:37:13,738 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 04:37:13,740 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local2084314112_0001
2016-01-05 04:37:13,741 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 04:37:56,444 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:37:56,450 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:37:56,740 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:37:56,771 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:37:56,851 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 2
2016-01-05 04:37:57,736 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local427233432_0001
2016-01-05 04:37:57,738 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 04:37:57,749 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 04:37:57,788 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 04:37:57,789 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local427233432_0001_m_000000_0
2016-01-05 04:37:57,816 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:37:57,857 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 04:37:57,862 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@59c208b0
2016-01-05 04:37:57,866 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors:0+44
2016-01-05 04:37:57,872 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:37:57,879 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:37:57,999 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:37:58,001 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:37:58,019 INFO org.apache.hadoop.fs.FSInputChecker: Found checksum error: b[0, 44]=312c340a332c350a362c350a372c340a332c340a352c370a362c340a322c330a342c350a362c340a332c340a
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Canopy/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:225)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:147)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:484)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:76)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:85)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:139)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:37:58,022 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local427233432_0001_m_000001_0
2016-01-05 04:37:58,022 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:37:58,024 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5c6ed322
2016-01-05 04:37:58,028 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors~:0+0
2016-01-05 04:37:58,031 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:37:58,032 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:37:58,201 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 04:37:58,203 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local427233432_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Canopy/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Canopy/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:225)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:147)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:484)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:76)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:85)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:139)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:37:58,739 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 04:37:58,741 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local427233432_0001
2016-01-05 04:37:58,743 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 04:38:38,742 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:38:38,753 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:38:38,952 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:38:38,982 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:38:39,066 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 2
2016-01-05 04:38:40,115 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local572924687_0001
2016-01-05 04:38:40,117 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 04:38:40,134 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 04:38:40,180 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 04:38:40,181 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local572924687_0001_m_000000_0
2016-01-05 04:38:40,253 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:38:40,353 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 04:38:40,367 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@583a5794
2016-01-05 04:38:40,374 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors:0+44
2016-01-05 04:38:40,406 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:38:40,415 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:38:40,575 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:38:40,575 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:38:40,618 INFO org.apache.hadoop.fs.FSInputChecker: Found checksum error: b[0, 44]=312c340a332c350a362c350a372c340a332c340a352c370a362c340a322c330a342c350a362c340a332c340a
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Canopy/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:225)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:147)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:484)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:76)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:85)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:139)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:38:40,623 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local572924687_0001_m_000001_0
2016-01-05 04:38:40,624 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:38:40,638 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@45e67e6a
2016-01-05 04:38:40,639 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors~:0+0
2016-01-05 04:38:40,641 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:38:40,642 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:38:40,970 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 04:38:40,971 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local572924687_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Canopy/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Canopy/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:225)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:147)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:484)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:76)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:85)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:139)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:38:41,123 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 04:38:41,127 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local572924687_0001
2016-01-05 04:38:41,128 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 04:40:49,878 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:40:49,883 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:40:50,054 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:40:50,071 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:40:50,130 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training1353486802/.staging/job_local1353486802_0001
2016-01-05 04:40:50,137 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/training/Desktop/canopy
2016-01-05 04:41:32,018 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:41:32,021 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:41:32,228 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:41:32,252 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:41:32,305 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training484191414/.staging/job_local484191414_0001
2016-01-05 04:41:32,308 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/training/Desktop/canopy/input
2016-01-05 04:42:18,362 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:42:18,370 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:42:18,589 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:42:18,612 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:42:18,650 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 2
2016-01-05 04:42:19,413 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1471115705_0001
2016-01-05 04:42:19,413 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 04:42:19,433 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 04:42:19,472 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 04:42:19,473 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1471115705_0001_m_000000_0
2016-01-05 04:42:19,508 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:42:19,546 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 04:42:19,603 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@59c208b0
2016-01-05 04:42:19,608 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors:0+44
2016-01-05 04:42:19,617 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:42:19,620 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:42:19,730 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:42:19,731 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:42:19,743 INFO org.apache.hadoop.fs.FSInputChecker: Found checksum error: b[0, 44]=312c340a332c350a362c350a372c340a332c340a352c370a362c340a322c330a342c350a362c340a332c340a
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Canopy/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:225)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:147)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:484)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:76)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:85)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:139)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:42:19,746 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1471115705_0001_m_000001_0
2016-01-05 04:42:19,746 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:42:19,749 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5c6ed322
2016-01-05 04:42:19,752 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/input/CanopyVectors~:0+0
2016-01-05 04:42:19,752 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:42:19,754 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:42:19,878 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 04:42:19,879 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1471115705_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Canopy/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Canopy/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:225)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:209)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:173)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:147)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:484)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:76)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:85)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:139)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 04:42:20,419 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 04:42:20,421 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1471115705_0001
2016-01-05 04:42:20,422 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 04:46:33,457 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:46:33,459 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:46:33,826 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:46:33,852 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:46:33,873 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training2142728892/.staging/job_local2142728892_0001
2016-01-05 04:46:33,876 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory /home/training/Desktop/Canopy/output already exists
2016-01-05 04:54:58,643 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 04:54:58,693 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 04:54:58,960 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 04:54:58,991 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 04:54:59,053 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 04:54:59,811 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local703340332_0001
2016-01-05 04:54:59,812 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 04:54:59,818 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 04:54:59,860 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 04:54:59,861 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local703340332_0001_m_000000_0
2016-01-05 04:54:59,896 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:54:59,938 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 04:55:00,004 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@249c2715
2016-01-05 04:55:00,010 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/Input/CanopyVectors:0+56
2016-01-05 04:55:00,019 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 04:55:00,023 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 04:55:00,132 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 04:55:00,133 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 04:55:00,176 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:55:00,177 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 04:55:00,195 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 04:55:00,197 INFO org.apache.hadoop.mapred.Task: Task:attempt_local703340332_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 04:55:00,221 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:55:00,221 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local703340332_0001_m_000000_0' done.
2016-01-05 04:55:00,224 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local703340332_0001_m_000000_0
2016-01-05 04:55:00,224 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 04:55:00,230 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 04:55:00,236 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@67ce85c4
2016-01-05 04:55:00,236 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:55:00,244 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 04:55:00,270 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 158 bytes
2016-01-05 04:55:00,271 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:55:00,299 INFO org.apache.hadoop.mapred.Task: Task:attempt_local703340332_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 04:55:00,300 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 04:55:00,300 INFO org.apache.hadoop.mapred.Task: Task attempt_local703340332_0001_r_000000_0 is allowed to commit now
2016-01-05 04:55:00,302 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local703340332_0001_r_000000_0' to /home/training/Desktop/Canopy/output
2016-01-05 04:55:00,303 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 04:55:00,303 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local703340332_0001_r_000000_0' done.
2016-01-05 04:55:00,817 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 04:55:00,818 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local703340332_0001
2016-01-05 04:55:00,822 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 04:55:00,823 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 04:55:00,823 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=620
2016-01-05 04:55:00,823 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=176726
2016-01-05 04:55:00,823 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 04:55:00,823 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 04:55:00,823 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 04:55:00,823 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 04:55:00,823 INFO org.apache.hadoop.mapred.JobClient:     Map input records=14
2016-01-05 04:55:00,824 INFO org.apache.hadoop.mapred.JobClient:     Map output records=6
2016-01-05 04:55:00,824 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=144
2016-01-05 04:55:00,824 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 04:55:00,824 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 04:55:00,825 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 04:55:00,825 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 04:55:00,825 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 04:55:00,825 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=6
2016-01-05 04:55:00,825 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=2
2016-01-05 04:55:00,826 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=12
2016-01-05 04:55:00,826 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 04:55:00,826 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 04:55:00,826 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 04:55:00,826 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:02:51,416 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:02:51,419 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:02:51,600 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:02:51,617 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:02:53,905 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training1990787222/.staging/job_local1990787222_0001
2016-01-05 05:02:53,919 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:java.io.IOException: Failed on local exception: com.google.protobuf.InvalidProtocolBufferException: Protocol message end-group tag did not match expected tag.; Host Details : local host is: "localhost.localdomain/127.0.0.1"; destination host is: "localhost":50070; 
2016-01-05 05:03:52,925 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:03:52,932 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:03:53,118 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:03:53,140 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:03:54,499 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training119872403/.staging/job_local119872403_0001
2016-01-05 05:03:54,499 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:java.io.IOException: Failed on local exception: com.google.protobuf.InvalidProtocolBufferException: Protocol message end-group tag did not match expected tag.; Host Details : local host is: "localhost.localdomain/127.0.0.1"; destination host is: "localhost.localdomain":50070; 
2016-01-05 05:05:06,462 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:05:06,474 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:05:06,646 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:05:06,663 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:05:06,720 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:05:07,563 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local464973384_0001
2016-01-05 05:05:07,565 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:05:07,607 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:05:07,663 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:05:07,667 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local464973384_0001_m_000000_0
2016-01-05 05:05:07,744 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:05:07,808 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:05:07,812 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@44908881
2016-01-05 05:05:07,817 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/Input/CanopyVectors:0+56
2016-01-05 05:05:07,825 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:05:07,828 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:05:08,112 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:05:08,115 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:05:08,463 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:05:08,464 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:05:08,495 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:05:08,497 INFO org.apache.hadoop.mapred.Task: Task:attempt_local464973384_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:05:08,519 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:05:08,519 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local464973384_0001_m_000000_0' done.
2016-01-05 05:05:08,520 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local464973384_0001_m_000000_0
2016-01-05 05:05:08,520 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:05:08,523 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:05:08,528 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5e29c58e
2016-01-05 05:05:08,528 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:05:08,532 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:05:08,582 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 0%
2016-01-05 05:05:08,604 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 158 bytes
2016-01-05 05:05:08,604 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:05:08,821 INFO org.apache.hadoop.mapred.Task: Task:attempt_local464973384_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:05:08,822 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:05:08,822 INFO org.apache.hadoop.mapred.Task: Task attempt_local464973384_0001_r_000000_0 is allowed to commit now
2016-01-05 05:05:08,824 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local464973384_0001_r_000000_0' to /home/training/Desktop/Canopy/output
2016-01-05 05:05:08,824 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:05:08,825 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local464973384_0001_r_000000_0' done.
2016-01-05 05:05:09,597 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:05:09,597 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local464973384_0001
2016-01-05 05:05:09,695 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 05:05:09,695 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:05:09,695 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=620
2016-01-05 05:05:09,695 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=177446
2016-01-05 05:05:09,695 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:05:09,695 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:05:09,696 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:05:09,696 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:05:09,696 INFO org.apache.hadoop.mapred.JobClient:     Map input records=14
2016-01-05 05:05:09,696 INFO org.apache.hadoop.mapred.JobClient:     Map output records=6
2016-01-05 05:05:09,696 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=144
2016-01-05 05:05:09,696 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 05:05:09,696 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:05:09,697 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:05:09,697 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:05:09,697 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:05:09,697 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=6
2016-01-05 05:05:09,697 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=2
2016-01-05 05:05:09,697 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=12
2016-01-05 05:05:09,697 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:05:09,697 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:05:09,698 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:05:09,698 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:09:25,453 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:09:25,466 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:09:25,656 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:09:25,695 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:09:25,719 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training68164496/.staging/job_local68164496_0001
2016-01-05 05:09:25,722 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory /home/training/Desktop/Canopy/output already exists
2016-01-05 05:10:30,430 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:10:30,439 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:10:30,696 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:10:30,716 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:10:30,750 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training2037282864/.staging/job_local2037282864_0001
2016-01-05 05:10:30,751 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory /home/training/Desktop/Canopy/output already exists
2016-01-05 05:12:08,400 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:12:08,417 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:12:08,612 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:12:08,617 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:12:08,735 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:12:08,751 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:12:08,764 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:12:09,225 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:12:09,226 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1412106659_0001
2016-01-05 05:12:09,237 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:12:09,429 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:12:09,430 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1412106659_0001_m_000000_0
2016-01-05 05:12:09,515 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:12:09,729 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:12:09,772 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@6ad3c65d
2016-01-05 05:12:09,802 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+44
2016-01-05 05:12:09,837 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:12:09,848 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:12:10,236 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 05:12:10,313 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:12:10,313 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:12:10,469 INFO org.apache.hadoop.fs.FSInputChecker: Found checksum error: b[0, 44]=312c340a332c350a362c350a372c340a332c340a352c370a362c340a322c330a342c350a362c340a332c340a
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:12:10,508 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:12:10,509 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1412106659_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:12:11,238 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1412106659_0001
2016-01-05 05:12:11,239 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 05:12:11,243 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:15:52,839 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:15:52,856 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:15:53,082 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:15:53,254 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:15:53,259 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:15:53,321 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:15:53,340 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:15:53,383 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:15:54,448 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1761785364_0001
2016-01-05 05:15:54,448 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:15:54,468 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:15:54,520 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:15:54,521 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1761785364_0001_m_000000_0
2016-01-05 05:15:54,614 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:15:54,742 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:15:54,776 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 05:15:54,807 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+44
2016-01-05 05:15:54,841 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:15:54,851 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:15:55,143 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:15:55,143 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:15:55,185 INFO org.apache.hadoop.fs.FSInputChecker: Found checksum error: b[0, 44]=312c340a332c350a362c350a372c340a332c340a352c370a362c340a322c330a342c350a362c340a332c340a
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:15:55,212 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:15:55,213 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1761785364_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:15:55,458 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 05:15:55,460 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1761785364_0001
2016-01-05 05:15:55,461 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 05:15:55,466 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:16:31,806 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:16:31,818 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:16:32,039 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:16:32,240 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:16:32,241 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:16:32,328 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:16:32,355 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:16:32,431 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:16:33,239 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1310513311_0001
2016-01-05 05:16:33,239 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:16:33,254 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:16:33,304 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:16:33,305 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1310513311_0001_m_000000_0
2016-01-05 05:16:33,385 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:16:33,525 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:16:33,555 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@700a4488
2016-01-05 05:16:33,560 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+44
2016-01-05 05:16:33,578 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:16:33,598 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:16:33,838 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:16:33,840 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:16:33,898 INFO org.apache.hadoop.fs.FSInputChecker: Found checksum error: b[0, 44]=312c340a332c350a362c350a372c340a332c340a352c370a362c340a322c330a342c350a362c340a332c340a
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:16:33,913 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:16:33,915 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1310513311_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:16:34,253 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 05:16:34,254 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1310513311_0001
2016-01-05 05:16:34,255 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 05:16:34,301 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:17:53,455 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:17:53,467 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:17:53,749 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:17:53,751 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:17:54,034 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:17:54,064 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:17:54,132 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:17:54,805 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1036700174_0001
2016-01-05 05:17:54,806 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:17:54,817 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:17:54,850 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:17:54,851 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1036700174_0001_m_000000_0
2016-01-05 05:17:54,928 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:17:55,038 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:17:55,061 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@ed0220c
2016-01-05 05:17:55,066 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+44
2016-01-05 05:17:55,123 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:17:55,126 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:17:55,357 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:17:55,359 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:17:55,402 INFO org.apache.hadoop.fs.FSInputChecker: Found checksum error: b[0, 44]=312c340a332c350a362c350a372c340a332c340a352c370a362c340a322c330a342c350a362c340a332c340a
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:17:55,414 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:17:55,415 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1036700174_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:18:22,363 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:18:22,372 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:18:22,648 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:18:22,654 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:18:22,805 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:18:22,833 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:18:22,863 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:18:23,417 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local229511868_0001
2016-01-05 05:18:23,419 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:18:23,428 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:18:23,468 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:18:23,469 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local229511868_0001_m_000000_0
2016-01-05 05:18:23,538 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:18:23,653 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:18:23,679 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@ed0220c
2016-01-05 05:18:23,698 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+44
2016-01-05 05:18:23,732 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:18:23,742 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:18:24,002 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:18:24,002 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:18:24,032 INFO org.apache.hadoop.fs.FSInputChecker: Found checksum error: b[0, 44]=312c340a332c350a362c350a372c340a332c340a352c370a362c340a322c330a342c350a362c340a332c340a
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:18:24,045 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:18:24,046 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local229511868_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:18:24,421 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 05:18:24,424 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local229511868_0001
2016-01-05 05:18:24,426 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 05:18:24,438 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:23:18,777 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:23:18,783 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:23:18,992 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:23:18,993 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:23:19,112 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:23:19,130 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:23:19,160 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:23:19,714 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local592281499_0001
2016-01-05 05:23:19,714 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:23:19,726 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:23:19,772 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:23:19,773 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local592281499_0001_m_000000_0
2016-01-05 05:23:19,884 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:23:20,016 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:23:20,049 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@51a19458
2016-01-05 05:23:20,052 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+44
2016-01-05 05:23:20,073 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:23:20,087 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:23:20,321 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:23:20,321 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:23:20,349 INFO org.apache.hadoop.fs.FSInputChecker: Found checksum error: b[0, 44]=312c340a332c350a362c350a372c340a332c340a352c370a362c340a322c330a342c350a362c340a332c340a
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:23:20,356 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:23:20,357 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local592281499_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:23:20,715 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 05:23:20,717 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local592281499_0001
2016-01-05 05:23:20,718 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 05:23:20,721 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:27:43,983 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:27:43,986 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:27:44,163 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:27:44,174 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:27:44,189 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:27:44,689 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local994509828_0001
2016-01-05 05:27:44,690 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:27:44,701 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:27:44,743 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:27:44,744 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local994509828_0001_m_000000_0
2016-01-05 05:27:44,795 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:27:44,893 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:27:44,965 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@3c3ac93e
2016-01-05 05:27:44,974 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+44
2016-01-05 05:27:44,999 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:27:45,011 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:27:45,192 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:27:45,193 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:27:45,248 INFO org.apache.hadoop.fs.FSInputChecker: Found checksum error: b[0, 44]=312c340a332c350a362c350a372c340a332c340a352c370a362c340a322c330a342c350a362c340a332c340a
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:27:45,267 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:27:45,268 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local994509828_0001
java.lang.Exception: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum error: file:/home/training/Desktop/Kmeans/input/CanopyVectors at 0 exp: 386673154 got: -737324040
	at org.apache.hadoop.fs.FSInputChecker.verifySums(FSInputChecker.java:320)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:276)
	at org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:211)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:229)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:193)
	at java.io.DataInputStream.readFully(DataInputStream.java:178)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:27:45,691 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 05:27:45,692 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local994509828_0001
2016-01-05 05:27:45,694 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 05:27:45,703 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:28:19,683 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:28:19,690 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:28:19,840 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:28:19,844 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:28:19,898 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:28:19,912 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:28:19,937 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:28:20,439 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:28:20,445 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1528297715_0001
2016-01-05 05:28:20,460 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:28:20,519 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:28:20,520 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1528297715_0001_m_000000_0
2016-01-05 05:28:20,596 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:28:20,721 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:28:20,744 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@1d96f4b5
2016-01-05 05:28:20,748 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+0
2016-01-05 05:28:20,772 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:28:20,784 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:28:21,072 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:28:21,072 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:28:21,109 WARN org.apache.hadoop.fs.FSInputChecker: Problem opening checksum file: file:/home/training/Desktop/Kmeans/input/CanopyVectors.  Ignoring exception: 
java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:147)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:334)
	at org.apache.hadoop.io.SequenceFile$Reader.openFile(SequenceFile.java:1787)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1707)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:28:21,119 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:28:21,119 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1528297715_0001
java.lang.Exception: java.io.EOFException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:28:21,456 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 05:28:21,457 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1528297715_0001
2016-01-05 05:28:21,458 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 05:28:21,461 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:30:08,165 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:30:08,183 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:30:08,194 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:30:08,361 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:30:08,367 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:30:08,409 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:30:08,430 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:30:08,468 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:30:08,985 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1188601113_0001
2016-01-05 05:30:08,987 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:30:08,998 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:30:09,033 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:30:09,034 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1188601113_0001_m_000000_0
2016-01-05 05:30:09,107 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:30:09,218 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:30:09,257 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@219ba640
2016-01-05 05:30:09,264 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+0
2016-01-05 05:30:09,303 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:30:09,315 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:30:09,599 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:30:09,599 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:30:09,635 WARN org.apache.hadoop.fs.FSInputChecker: Problem opening checksum file: file:/home/training/Desktop/Kmeans/input/CanopyVectors.  Ignoring exception: 
java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:147)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:334)
	at org.apache.hadoop.io.SequenceFile$Reader.openFile(SequenceFile.java:1787)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1707)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:30:09,646 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:30:09,647 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1188601113_0001
java.lang.Exception: java.io.EOFException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:50)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:479)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:672)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 05:30:09,996 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 05:30:09,997 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1188601113_0001
2016-01-05 05:30:09,998 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 05:30:10,015 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:30:39,275 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:30:39,284 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:30:39,446 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:30:39,452 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:30:39,497 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:30:39,508 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:30:39,537 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:30:40,212 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1609343328_0001
2016-01-05 05:30:40,212 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:30:40,232 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:30:40,295 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:30:40,296 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1609343328_0001_m_000000_0
2016-01-05 05:30:40,370 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:30:40,471 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:30:40,492 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@1f57ea4a
2016-01-05 05:30:40,496 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+530
2016-01-05 05:30:40,517 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:30:40,527 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:30:40,703 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:30:40,706 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:30:40,743 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:30:40,757 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:30:40,771 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:30:40,772 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:30:40,807 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:30:40,818 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1609343328_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:30:40,833 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:30:40,834 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1609343328_0001_m_000000_0' done.
2016-01-05 05:30:40,834 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1609343328_0001_m_000000_0
2016-01-05 05:30:40,834 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:30:40,837 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:30:40,852 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@59e184cb
2016-01-05 05:30:40,853 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:30:40,868 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:30:40,923 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:30:40,925 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:30:40,960 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1609343328_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:30:40,961 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:30:40,963 INFO org.apache.hadoop.mapred.Task: Task attempt_local1609343328_0001_r_000000_0 is allowed to commit now
2016-01-05 05:30:40,973 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1609343328_0001_r_000000_0' to /home/training/Desktop/output
2016-01-05 05:30:40,974 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:30:40,974 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1609343328_0001_r_000000_0' done.
2016-01-05 05:30:41,232 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:30:41,235 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1609343328_0001
2016-01-05 05:30:41,242 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:30:41,242 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:30:41,243 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2256
2016-01-05 05:30:41,243 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181608
2016-01-05 05:30:41,243 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:30:41,243 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:30:41,243 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:30:41,243 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:30:41,244 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:30:41,244 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:30:41,244 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:30:41,244 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 05:30:41,244 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:30:41,245 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:30:41,245 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:30:41,245 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:30:41,245 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:30:41,247 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:30:41,247 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:30:41,247 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:30:41,247 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:30:41,248 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:30:41,248 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:30:41,248 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:30:41,248 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:30:41,282 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:30:41,283 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:30:41,284 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:30:41,291 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training1216729895/.staging/job_local1216729895_0002
2016-01-05 05:30:41,291 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/training/Desktop/output1
2016-01-05 05:31:55,622 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:31:55,629 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:31:55,790 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:31:55,795 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:31:55,841 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:31:55,857 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:31:55,885 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:31:56,336 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local801341023_0001
2016-01-05 05:31:56,338 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:31:56,351 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:31:56,389 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:31:56,390 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local801341023_0001_m_000000_0
2016-01-05 05:31:56,440 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:31:56,538 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:31:56,577 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@1c7e2da
2016-01-05 05:31:56,588 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+530
2016-01-05 05:31:56,641 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:31:56,655 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:31:56,969 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:31:56,974 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:31:57,018 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:31:57,043 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:31:57,054 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:31:57,065 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:31:57,127 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:31:57,129 INFO org.apache.hadoop.mapred.Task: Task:attempt_local801341023_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:31:57,179 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:31:57,180 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local801341023_0001_m_000000_0' done.
2016-01-05 05:31:57,180 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local801341023_0001_m_000000_0
2016-01-05 05:31:57,180 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:31:57,194 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:31:57,222 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@a68cb6b
2016-01-05 05:31:57,225 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:31:57,240 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:31:57,282 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:31:57,283 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:31:57,338 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 0%
2016-01-05 05:31:57,346 INFO org.apache.hadoop.mapred.Task: Task:attempt_local801341023_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:31:57,347 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:31:57,349 INFO org.apache.hadoop.mapred.Task: Task attempt_local801341023_0001_r_000000_0 is allowed to commit now
2016-01-05 05:31:57,353 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local801341023_0001_r_000000_0' to /home/training/Desktop/output
2016-01-05 05:31:57,357 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:31:57,357 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local801341023_0001_r_000000_0' done.
2016-01-05 05:31:58,342 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:31:58,342 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local801341023_0001
2016-01-05 05:31:58,348 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:31:58,348 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:31:58,348 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2256
2016-01-05 05:31:58,348 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181600
2016-01-05 05:31:58,349 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:31:58,349 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:31:58,349 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:31:58,349 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:31:58,349 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:31:58,349 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:31:58,349 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:31:58,349 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 05:31:58,350 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:31:58,350 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:31:58,350 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:31:58,350 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:31:58,351 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:31:58,352 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:31:58,352 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:31:58,352 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:31:58,352 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:31:58,352 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:31:58,352 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:31:58,352 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:31:58,352 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:31:58,466 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:31:58,467 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:31:58,476 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:31:58,479 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training914084901/.staging/job_local914084901_0002
2016-01-05 05:31:58,480 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/training/Desktop/output1
2016-01-05 05:35:44,231 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:35:44,244 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:35:44,417 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:35:44,418 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:35:44,459 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:35:44,484 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:35:44,513 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:35:45,128 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1660972136_0001
2016-01-05 05:35:45,130 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:35:45,167 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:35:45,236 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:35:45,237 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1660972136_0001_m_000000_0
2016-01-05 05:35:45,330 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:35:45,427 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:35:45,449 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@69fe571f
2016-01-05 05:35:45,457 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+530
2016-01-05 05:35:45,475 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:35:45,493 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:35:45,675 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:35:45,676 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:35:45,719 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:35:45,731 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:35:45,738 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:35:45,740 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:35:45,763 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:35:45,771 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1660972136_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:35:45,781 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:35:45,781 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1660972136_0001_m_000000_0' done.
2016-01-05 05:35:45,781 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1660972136_0001_m_000000_0
2016-01-05 05:35:45,785 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:35:45,788 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:35:45,802 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@478e4327
2016-01-05 05:35:45,802 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:35:45,809 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:35:45,838 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:35:45,839 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:35:45,872 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1660972136_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:35:45,878 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:35:45,878 INFO org.apache.hadoop.mapred.Task: Task attempt_local1660972136_0001_r_000000_0 is allowed to commit now
2016-01-05 05:35:45,886 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1660972136_0001_r_000000_0' to /home/training/Desktop/output
2016-01-05 05:35:45,888 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:35:45,888 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1660972136_0001_r_000000_0' done.
2016-01-05 05:35:46,140 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:35:46,141 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1660972136_0001
2016-01-05 05:35:46,148 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:35:46,148 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:35:46,148 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2256
2016-01-05 05:35:46,149 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181608
2016-01-05 05:35:46,149 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:35:46,149 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:35:46,149 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:35:46,149 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:35:46,149 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:35:46,149 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:35:46,149 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:35:46,150 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 05:35:46,150 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:35:46,150 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:35:46,150 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:35:46,150 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:35:46,151 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:35:46,151 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:35:46,151 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:35:46,151 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:35:46,152 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:35:46,152 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:35:46,153 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:35:46,153 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:35:46,153 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:35:46,188 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:35:46,189 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:35:46,190 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:35:46,192 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training360394126/.staging/job_local360394126_0002
2016-01-05 05:35:46,192 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/training/Desktop/output1
2016-01-05 05:49:47,094 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:49:47,105 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:49:47,537 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:49:47,540 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:49:47,645 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:49:47,692 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:49:47,768 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:49:48,620 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1223389987_0001
2016-01-05 05:49:48,620 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:49:48,646 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:49:48,718 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:49:48,719 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1223389987_0001_m_000000_0
2016-01-05 05:49:48,811 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:49:48,949 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:49:48,973 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@67ce85c4
2016-01-05 05:49:48,989 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 05:49:49,025 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:49:49,041 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:49:49,244 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:49:49,245 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:49:49,355 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:49:49,379 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:49:49,402 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:49,402 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:49:49,488 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:49:49,500 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1223389987_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:49:49,529 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:49,535 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1223389987_0001_m_000000_0' done.
2016-01-05 05:49:49,535 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1223389987_0001_m_000000_0
2016-01-05 05:49:49,535 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:49:49,544 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:49:49,568 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@a0430b6
2016-01-05 05:49:49,568 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:49,607 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:49:49,643 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 0%
2016-01-05 05:49:49,677 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:49:49,677 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:49,754 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1223389987_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:49:49,759 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:49,760 INFO org.apache.hadoop.mapred.Task: Task attempt_local1223389987_0001_r_000000_0 is allowed to commit now
2016-01-05 05:49:49,775 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1223389987_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 05:49:49,775 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:49:49,776 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1223389987_0001_r_000000_0' done.
2016-01-05 05:49:50,650 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:49:50,650 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1223389987_0001
2016-01-05 05:49:50,659 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:49:50,659 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:49:50,660 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2278
2016-01-05 05:49:50,660 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181654
2016-01-05 05:49:50,660 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:49:50,660 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:49:50,660 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:49:50,660 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:49:50,661 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:49:50,661 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:49:50,661 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:49:50,661 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 05:49:50,661 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:49:50,662 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:49:50,662 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:49:50,662 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:49:50,662 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:49:50,662 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:49:50,662 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:49:50,663 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:49:50,663 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:49:50,663 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:49:50,663 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:49:50,663 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:49:50,663 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:49:50,761 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:49:50,765 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:49:50,771 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:49:50,779 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:49:50,979 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local75088709_0002
2016-01-05 05:49:50,982 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:49:50,983 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:49:50,993 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:49:50,994 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local75088709_0002_m_000000_0
2016-01-05 05:49:50,994 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:49:51,001 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@7bcd280b
2016-01-05 05:49:51,009 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_1/part-r-00000:0+493
2016-01-05 05:49:51,010 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:49:51,014 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:49:51,110 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:49:51,111 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:49:51,132 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:51,139 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:49:51,146 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:49:51,188 INFO org.apache.hadoop.mapred.Task: Task:attempt_local75088709_0002_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:49:51,190 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:51,190 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local75088709_0002_m_000000_0' done.
2016-01-05 05:49:51,190 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local75088709_0002_m_000000_0
2016-01-05 05:49:51,190 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:49:51,191 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:49:51,206 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@30b3f9b8
2016-01-05 05:49:51,207 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:51,213 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:49:51,216 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:49:51,216 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:51,232 INFO org.apache.hadoop.mapred.Task: Task:attempt_local75088709_0002_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:49:51,232 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:51,232 INFO org.apache.hadoop.mapred.Task: Task attempt_local75088709_0002_r_000000_0 is allowed to commit now
2016-01-05 05:49:51,235 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local75088709_0002_r_000000_0' to files/clustering/depth_2
2016-01-05 05:49:51,240 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:49:51,240 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local75088709_0002_r_000000_0' done.
2016-01-05 05:49:51,982 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:49:51,982 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local75088709_0002
2016-01-05 05:49:51,993 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:49:51,994 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:49:51,994 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=4876
2016-01-05 05:49:51,994 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=362516
2016-01-05 05:49:51,994 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:49:51,994 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:49:51,995 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:49:51,995 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:49:51,995 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:49:51,995 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:49:51,995 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:49:51,995 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:49:51,997 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:49:51,998 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:49:51,998 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:49:51,998 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:49:51,998 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:49:51,998 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:49:51,999 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:49:51,999 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:49:51,999 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:49:51,999 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:49:51,999 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:49:51,999 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:49:51,999 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:49:52,098 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:49:52,101 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:49:52,102 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:49:52,105 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:49:52,181 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1326112599_0003
2016-01-05 05:49:52,181 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:49:52,185 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:49:52,208 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:49:52,209 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1326112599_0003_m_000000_0
2016-01-05 05:49:52,209 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:49:52,216 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@2321b59a
2016-01-05 05:49:52,219 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_2/part-r-00000:0+493
2016-01-05 05:49:52,225 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:49:52,226 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:49:52,362 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:49:52,363 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:49:52,381 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:52,381 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:49:52,388 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:49:52,391 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1326112599_0003_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:49:52,394 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:52,395 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1326112599_0003_m_000000_0' done.
2016-01-05 05:49:52,395 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1326112599_0003_m_000000_0
2016-01-05 05:49:52,395 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:49:52,396 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:49:52,406 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@786db724
2016-01-05 05:49:52,407 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:52,408 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:49:52,409 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:49:52,409 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:52,421 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1326112599_0003_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:49:52,421 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:49:52,422 INFO org.apache.hadoop.mapred.Task: Task attempt_local1326112599_0003_r_000000_0 is allowed to commit now
2016-01-05 05:49:52,424 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1326112599_0003_r_000000_0' to files/clustering/depth_3
2016-01-05 05:49:52,425 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:49:52,425 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1326112599_0003_r_000000_0' done.
2016-01-05 05:49:53,182 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:49:53,182 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1326112599_0003
2016-01-05 05:49:53,186 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 05:49:53,186 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:49:53,186 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=7474
2016-01-05 05:49:53,186 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=543394
2016-01-05 05:49:53,187 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:49:53,187 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:49:53,187 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:49:53,187 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:49:53,188 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:49:53,188 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:49:53,188 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:49:53,188 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:49:53,188 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:49:53,189 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:49:53,189 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:49:53,189 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:49:53,189 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:49:53,190 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:49:53,190 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:49:53,190 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:49:53,190 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:49:53,190 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:49:53,190 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=440270848
2016-01-05 05:49:53,195 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:49:53,196 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 05:49:53,196 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 05:49:53,197 INFO Kmeans.KMeansClusteringJob: SHAY3
2016-01-05 05:49:53,197 INFO Kmeans.KMeansClusteringJob: FOUND hdfs://0.0.0.0/user/cloudera/files/clustering/depth_3/part-r-00000
2016-01-05 05:49:53,197 INFO Kmeans.KMeansClusteringJob: SHAY4
2016-01-05 05:52:47,647 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:52:47,654 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:52:47,691 INFO Kmeans.KMeansClusteringJob: SHAY5
2016-01-05 05:52:47,691 INFO Kmeans.KMeansClusteringJob: SHAY6
2016-01-05 05:52:47,714 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 05:52:47,714 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 05:52:48,022 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:52:48,341 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:52:48,347 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:52:48,602 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:52:48,619 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:52:48,649 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:52:49,402 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1802511959_0001
2016-01-05 05:52:49,403 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:52:49,411 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:52:49,458 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:52:49,460 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1802511959_0001_m_000000_0
2016-01-05 05:52:49,497 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:52:49,552 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:52:49,597 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@40f892a4
2016-01-05 05:52:49,600 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 05:52:49,608 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:52:49,612 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:52:49,735 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:52:49,737 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:52:49,749 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:52:49,752 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:49,753 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:52:49,784 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:52:49,796 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1802511959_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:52:49,806 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:49,807 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1802511959_0001_m_000000_0' done.
2016-01-05 05:52:49,807 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1802511959_0001_m_000000_0
2016-01-05 05:52:49,807 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:52:49,812 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:52:49,819 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@6ee1dac2
2016-01-05 05:52:49,821 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:49,828 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:52:49,848 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:52:49,851 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:49,887 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1802511959_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:52:49,888 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:49,888 INFO org.apache.hadoop.mapred.Task: Task attempt_local1802511959_0001_r_000000_0 is allowed to commit now
2016-01-05 05:52:49,891 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1802511959_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 05:52:49,891 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:52:49,892 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1802511959_0001_r_000000_0' done.
2016-01-05 05:52:50,410 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:52:50,412 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1802511959_0001
2016-01-05 05:52:50,429 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:52:50,429 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:52:50,430 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2708
2016-01-05 05:52:50,430 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181654
2016-01-05 05:52:50,430 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:52:50,430 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:52:50,430 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:52:50,431 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:52:50,431 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:52:50,431 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:52:50,431 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:52:50,431 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 05:52:50,432 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:52:50,432 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:52:50,432 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:52:50,432 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:52:50,432 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:52:50,433 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:52:50,433 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:52:50,433 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:52:50,433 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:52:50,433 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:52:50,433 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:52:50,434 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:52:50,434 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:52:50,539 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:52:50,546 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:52:50,552 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:52:50,563 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:52:50,832 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local70415173_0002
2016-01-05 05:52:50,833 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:52:50,834 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:52:50,847 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:52:50,848 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local70415173_0002_m_000000_0
2016-01-05 05:52:50,848 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:52:50,854 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5dde45e2
2016-01-05 05:52:50,860 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_1/part-r-00000:0+493
2016-01-05 05:52:50,865 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:52:50,866 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:52:50,994 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:52:50,994 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:52:51,041 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:51,042 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:52:51,048 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:52:51,057 INFO org.apache.hadoop.mapred.Task: Task:attempt_local70415173_0002_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:52:51,061 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:51,065 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local70415173_0002_m_000000_0' done.
2016-01-05 05:52:51,066 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local70415173_0002_m_000000_0
2016-01-05 05:52:51,066 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:52:51,066 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:52:51,076 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@7a354749
2016-01-05 05:52:51,077 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:51,078 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:52:51,088 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:52:51,089 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:51,114 INFO org.apache.hadoop.mapred.Task: Task:attempt_local70415173_0002_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:52:51,117 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:51,118 INFO org.apache.hadoop.mapred.Task: Task attempt_local70415173_0002_r_000000_0 is allowed to commit now
2016-01-05 05:52:51,125 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local70415173_0002_r_000000_0' to files/clustering/depth_2
2016-01-05 05:52:51,131 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:52:51,131 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local70415173_0002_r_000000_0' done.
2016-01-05 05:52:51,834 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:52:51,834 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local70415173_0002
2016-01-05 05:52:51,837 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:52:51,837 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:52:51,837 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=5306
2016-01-05 05:52:51,837 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=362516
2016-01-05 05:52:51,837 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:52:51,838 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:52:51,838 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:52:51,838 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:52:51,838 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:52:51,838 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:52:51,838 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:52:51,839 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:52:51,839 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:52:51,839 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:52:51,839 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:52:51,839 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:52:51,839 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:52:51,840 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:52:51,840 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:52:51,840 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:52:51,840 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:52:51,840 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:52:51,840 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:52:51,841 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:52:51,841 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:52:51,910 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:52:51,916 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:52:51,925 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:52:51,931 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:52:52,045 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1059700940_0003
2016-01-05 05:52:52,048 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:52:52,051 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:52:52,061 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:52:52,065 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1059700940_0003_m_000000_0
2016-01-05 05:52:52,066 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:52:52,069 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@c569c60
2016-01-05 05:52:52,072 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_2/part-r-00000:0+493
2016-01-05 05:52:52,072 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:52:52,073 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:52:52,292 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:52:52,293 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:52:52,312 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:52,312 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:52:52,315 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:52:52,320 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1059700940_0003_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:52:52,321 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:52,321 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1059700940_0003_m_000000_0' done.
2016-01-05 05:52:52,322 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1059700940_0003_m_000000_0
2016-01-05 05:52:52,322 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:52:52,322 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:52:52,333 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@6986dda3
2016-01-05 05:52:52,333 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:52,334 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:52:52,335 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:52:52,335 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:52,342 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1059700940_0003_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:52:52,343 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:52:52,343 INFO org.apache.hadoop.mapred.Task: Task attempt_local1059700940_0003_r_000000_0 is allowed to commit now
2016-01-05 05:52:52,345 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1059700940_0003_r_000000_0' to files/clustering/depth_3
2016-01-05 05:52:52,346 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:52:52,346 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1059700940_0003_r_000000_0' done.
2016-01-05 05:52:53,046 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:52:53,046 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1059700940_0003
2016-01-05 05:52:53,052 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 05:52:53,052 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:52:53,052 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=7904
2016-01-05 05:52:53,053 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=543394
2016-01-05 05:52:53,053 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:52:53,053 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:52:53,053 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:52:53,053 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:52:53,053 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:52:53,053 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:52:53,054 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:52:53,054 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:52:53,054 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:52:53,054 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:52:53,054 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:52:53,055 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:52:53,055 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:52:53,055 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:52:53,055 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:52:53,055 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:52:53,055 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:52:53,056 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:52:53,056 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=440270848
2016-01-05 05:52:53,064 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:52:53,068 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 05:52:53,069 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 05:52:53,069 INFO Kmeans.KMeansClusteringJob: SHAY3
2016-01-05 05:52:53,069 INFO Kmeans.KMeansClusteringJob: FOUND hdfs://0.0.0.0/user/cloudera/files/clustering/depth_3/part-r-00000
2016-01-05 05:52:53,069 INFO Kmeans.KMeansClusteringJob: SHAY4
2016-01-05 05:53:57,193 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:53:57,205 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:53:57,289 INFO Kmeans.KMeansClusteringJob: SHAY5
2016-01-05 05:53:57,291 INFO Kmeans.KMeansClusteringJob: SHAY6
2016-01-05 05:53:57,301 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 05:53:57,306 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 05:53:57,627 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:53:57,949 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:53:57,953 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:53:58,043 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:53:58,078 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:53:58,120 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:53:58,892 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:53:58,895 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local489533228_0001
2016-01-05 05:53:58,910 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:53:58,951 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:53:58,953 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local489533228_0001_m_000000_0
2016-01-05 05:53:59,042 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:53:59,163 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:53:59,181 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 05:53:59,184 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 05:53:59,200 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:53:59,206 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:53:59,404 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:53:59,405 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:53:59,430 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:53:59,439 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:53:59,440 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:53:59,464 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:53:59,470 INFO org.apache.hadoop.mapred.Task: Task:attempt_local489533228_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:53:59,487 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:53:59,488 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local489533228_0001_m_000000_0' done.
2016-01-05 05:53:59,488 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local489533228_0001_m_000000_0
2016-01-05 05:53:59,488 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:53:59,494 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:53:59,519 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@3c3a1834
2016-01-05 05:53:59,520 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:53:59,533 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:53:59,567 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:53:59,568 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:53:59,608 INFO org.apache.hadoop.mapred.Task: Task:attempt_local489533228_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:53:59,615 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:53:59,620 INFO org.apache.hadoop.mapred.Task: Task attempt_local489533228_0001_r_000000_0 is allowed to commit now
2016-01-05 05:53:59,632 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local489533228_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 05:53:59,633 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:53:59,634 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local489533228_0001_r_000000_0' done.
2016-01-05 05:53:59,903 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:53:59,906 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local489533228_0001
2016-01-05 05:53:59,920 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:53:59,921 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:53:59,921 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2708
2016-01-05 05:53:59,921 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181646
2016-01-05 05:53:59,921 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:53:59,922 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:53:59,922 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:53:59,922 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:53:59,922 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:53:59,923 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:53:59,923 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:53:59,923 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 05:53:59,923 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:53:59,924 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:53:59,924 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:53:59,924 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:53:59,924 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:53:59,924 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:53:59,925 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:53:59,925 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:53:59,925 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:53:59,925 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:53:59,925 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:53:59,925 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:53:59,926 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:54:00,051 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:54:00,067 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:54:00,073 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:54:00,083 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:54:00,411 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1655521388_0002
2016-01-05 05:54:00,413 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:54:00,414 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:54:00,434 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:54:00,435 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1655521388_0002_m_000000_0
2016-01-05 05:54:00,435 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:54:00,447 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@45cbda0a
2016-01-05 05:54:00,449 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_1/part-r-00000:0+493
2016-01-05 05:54:00,449 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:54:00,454 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:54:00,566 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:54:00,579 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:54:00,617 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:00,630 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:54:00,647 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:54:00,649 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1655521388_0002_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:54:00,660 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:00,660 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1655521388_0002_m_000000_0' done.
2016-01-05 05:54:00,660 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1655521388_0002_m_000000_0
2016-01-05 05:54:00,661 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:54:00,661 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:54:00,681 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5dd2b9b7
2016-01-05 05:54:00,687 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:00,697 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:54:00,703 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:54:00,703 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:00,772 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1655521388_0002_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:54:00,773 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:00,780 INFO org.apache.hadoop.mapred.Task: Task attempt_local1655521388_0002_r_000000_0 is allowed to commit now
2016-01-05 05:54:00,782 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1655521388_0002_r_000000_0' to files/clustering/depth_2
2016-01-05 05:54:00,789 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:54:00,789 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1655521388_0002_r_000000_0' done.
2016-01-05 05:54:01,413 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:54:01,414 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1655521388_0002
2016-01-05 05:54:01,416 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:54:01,417 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:54:01,417 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=5306
2016-01-05 05:54:01,417 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=362524
2016-01-05 05:54:01,417 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:54:01,417 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:54:01,417 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:54:01,418 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:54:01,418 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:54:01,418 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:54:01,418 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:54:01,418 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:54:01,419 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:54:01,419 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:54:01,419 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:54:01,419 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:54:01,419 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:54:01,420 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:54:01,420 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:54:01,420 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:54:01,420 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:54:01,420 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:54:01,421 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:54:01,421 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:54:01,422 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:54:01,460 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:54:01,462 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:54:01,463 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:54:01,465 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:54:01,611 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1844235852_0003
2016-01-05 05:54:01,612 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:54:01,613 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:54:01,630 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:54:01,631 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1844235852_0003_m_000000_0
2016-01-05 05:54:01,631 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:54:01,636 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@6639c8c1
2016-01-05 05:54:01,643 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_2/part-r-00000:0+493
2016-01-05 05:54:01,644 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:54:01,646 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:54:01,728 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:54:01,733 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:54:01,758 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:01,761 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:54:01,764 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:54:01,767 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1844235852_0003_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:54:01,768 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:01,769 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1844235852_0003_m_000000_0' done.
2016-01-05 05:54:01,769 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1844235852_0003_m_000000_0
2016-01-05 05:54:01,769 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:54:01,770 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:54:01,774 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@2d20dbf3
2016-01-05 05:54:01,775 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:01,776 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:54:01,776 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:54:01,776 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:01,792 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1844235852_0003_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:54:01,793 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:01,794 INFO org.apache.hadoop.mapred.Task: Task attempt_local1844235852_0003_r_000000_0 is allowed to commit now
2016-01-05 05:54:01,796 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1844235852_0003_r_000000_0' to files/clustering/depth_3
2016-01-05 05:54:01,796 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:54:01,796 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1844235852_0003_r_000000_0' done.
2016-01-05 05:54:02,612 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:54:02,612 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1844235852_0003
2016-01-05 05:54:02,616 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 05:54:02,616 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:54:02,616 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=7904
2016-01-05 05:54:02,616 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=543402
2016-01-05 05:54:02,617 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:54:02,617 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:54:02,617 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:54:02,617 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:54:02,617 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:54:02,617 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:54:02,618 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:54:02,618 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:54:02,618 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:54:02,618 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:54:02,618 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:54:02,619 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:54:02,619 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:54:02,619 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:54:02,619 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:54:02,619 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:54:02,619 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:54:02,620 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:54:02,620 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=440270848
2016-01-05 05:54:02,623 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:54:02,624 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 05:54:02,624 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 05:54:02,624 INFO Kmeans.KMeansClusteringJob: SHAY3
2016-01-05 05:54:02,624 INFO Kmeans.KMeansClusteringJob: FOUND hdfs://0.0.0.0/user/cloudera/files/clustering/depth_3/part-r-00000
2016-01-05 05:54:02,624 INFO Kmeans.KMeansClusteringJob: SHAY4
2016-01-05 05:54:49,603 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:54:49,616 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:54:49,675 INFO Kmeans.KMeansClusteringJob: SHAY5
2016-01-05 05:54:49,675 INFO Kmeans.KMeansClusteringJob: SHAY6
2016-01-05 05:54:49,677 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 05:54:49,685 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 05:54:50,021 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:54:50,479 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:54:50,481 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:54:50,622 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:54:50,659 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:54:50,723 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:54:51,800 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:54:51,802 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local531131031_0001
2016-01-05 05:54:51,817 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:54:51,867 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:54:51,871 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local531131031_0001_m_000000_0
2016-01-05 05:54:51,967 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:54:52,089 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:54:52,114 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@3e78aa80
2016-01-05 05:54:52,118 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 05:54:52,138 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:54:52,151 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:54:52,316 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:54:52,317 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:54:52,347 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:54:52,353 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:52,357 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:54:52,400 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:54:52,408 INFO org.apache.hadoop.mapred.Task: Task:attempt_local531131031_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:54:52,438 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:52,439 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local531131031_0001_m_000000_0' done.
2016-01-05 05:54:52,440 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local531131031_0001_m_000000_0
2016-01-05 05:54:52,440 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:54:52,449 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:54:52,465 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@54083e1e
2016-01-05 05:54:52,468 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:52,484 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:54:52,515 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:54:52,516 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:52,598 INFO org.apache.hadoop.mapred.Task: Task:attempt_local531131031_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:54:52,603 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:52,604 INFO org.apache.hadoop.mapred.Task: Task attempt_local531131031_0001_r_000000_0 is allowed to commit now
2016-01-05 05:54:52,616 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local531131031_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 05:54:52,617 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:54:52,617 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local531131031_0001_r_000000_0' done.
2016-01-05 05:54:52,811 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:54:52,814 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local531131031_0001
2016-01-05 05:54:52,838 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:54:52,838 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:54:52,838 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2708
2016-01-05 05:54:52,838 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181646
2016-01-05 05:54:52,839 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:54:52,839 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:54:52,839 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:54:52,839 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:54:52,839 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:54:52,840 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:54:52,840 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:54:52,840 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 05:54:52,847 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:54:52,847 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:54:52,847 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:54:52,847 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:54:52,847 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:54:52,847 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:54:52,848 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:54:52,848 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:54:52,848 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:54:52,848 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:54:52,848 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:54:52,848 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:54:52,848 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:54:53,039 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:54:53,048 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:54:53,055 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:54:53,073 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:54:53,381 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local365243774_0002
2016-01-05 05:54:53,382 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:54:53,383 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:54:53,395 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:54:53,395 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local365243774_0002_m_000000_0
2016-01-05 05:54:53,398 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:54:53,405 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5bd6fbb3
2016-01-05 05:54:53,411 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_1/part-r-00000:0+493
2016-01-05 05:54:53,412 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:54:53,413 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:54:53,535 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:54:53,546 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:54:53,581 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:53,586 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:54:53,594 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:54:53,614 INFO org.apache.hadoop.mapred.Task: Task:attempt_local365243774_0002_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:54:53,622 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:53,622 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local365243774_0002_m_000000_0' done.
2016-01-05 05:54:53,622 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local365243774_0002_m_000000_0
2016-01-05 05:54:53,624 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:54:53,625 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:54:53,653 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@19958bf9
2016-01-05 05:54:53,655 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:53,657 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:54:53,670 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:54:53,671 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:53,726 INFO org.apache.hadoop.mapred.Task: Task:attempt_local365243774_0002_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:54:53,727 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:53,733 INFO org.apache.hadoop.mapred.Task: Task attempt_local365243774_0002_r_000000_0 is allowed to commit now
2016-01-05 05:54:53,745 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local365243774_0002_r_000000_0' to files/clustering/depth_2
2016-01-05 05:54:53,749 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:54:53,750 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local365243774_0002_r_000000_0' done.
2016-01-05 05:54:54,383 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:54:54,383 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local365243774_0002
2016-01-05 05:54:54,386 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:54:54,386 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:54:54,386 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=5306
2016-01-05 05:54:54,386 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=362516
2016-01-05 05:54:54,387 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:54:54,387 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:54:54,387 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:54:54,387 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:54:54,387 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:54:54,387 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:54:54,388 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:54:54,388 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:54:54,388 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:54:54,388 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:54:54,388 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:54:54,389 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:54:54,389 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:54:54,389 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:54:54,389 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:54:54,389 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:54:54,389 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:54:54,390 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:54:54,390 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:54:54,390 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:54:54,390 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:54:54,432 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:54:54,434 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:54:54,435 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:54:54,438 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:54:54,570 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local178992370_0003
2016-01-05 05:54:54,571 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:54:54,572 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:54:54,595 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:54:54,595 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local178992370_0003_m_000000_0
2016-01-05 05:54:54,595 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:54:54,600 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@7a354749
2016-01-05 05:54:54,605 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_2/part-r-00000:0+493
2016-01-05 05:54:54,609 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:54:54,609 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:54:54,716 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:54:54,717 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:54:54,735 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:54,736 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:54:54,746 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:54:54,750 INFO org.apache.hadoop.mapred.Task: Task:attempt_local178992370_0003_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:54:54,751 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:54,751 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local178992370_0003_m_000000_0' done.
2016-01-05 05:54:54,752 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local178992370_0003_m_000000_0
2016-01-05 05:54:54,752 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:54:54,754 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:54:54,762 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@319da967
2016-01-05 05:54:54,763 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:54,764 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:54:54,765 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:54:54,765 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:54,788 INFO org.apache.hadoop.mapred.Task: Task:attempt_local178992370_0003_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:54:54,789 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:54:54,789 INFO org.apache.hadoop.mapred.Task: Task attempt_local178992370_0003_r_000000_0 is allowed to commit now
2016-01-05 05:54:54,800 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local178992370_0003_r_000000_0' to files/clustering/depth_3
2016-01-05 05:54:54,803 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:54:54,803 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local178992370_0003_r_000000_0' done.
2016-01-05 05:54:55,571 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:54:55,571 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local178992370_0003
2016-01-05 05:54:55,575 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 05:54:55,575 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:54:55,575 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=7904
2016-01-05 05:54:55,575 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=543386
2016-01-05 05:54:55,575 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:54:55,576 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:54:55,576 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:54:55,576 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:54:55,576 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:54:55,576 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:54:55,576 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:54:55,577 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:54:55,577 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:54:55,577 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:54:55,577 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:54:55,577 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:54:55,577 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:54:55,578 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:54:55,578 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:54:55,578 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:54:55,578 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:54:55,578 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:54:55,579 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=440270848
2016-01-05 05:54:55,582 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:54:55,585 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 05:54:55,588 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 05:54:55,588 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 05:54:55,588 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 05:55:59,144 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:55:59,147 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:55:59,165 INFO Kmeans.KMeansClusteringJob: SHAY5
2016-01-05 05:55:59,165 INFO Kmeans.KMeansClusteringJob: SHAY6
2016-01-05 05:55:59,167 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 05:55:59,167 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 05:55:59,329 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:55:59,552 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:55:59,554 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:55:59,618 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:55:59,640 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:55:59,681 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:56:00,300 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:56:00,303 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local303384604_0001
2016-01-05 05:56:00,344 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:56:00,395 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:56:00,395 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local303384604_0001_m_000000_0
2016-01-05 05:56:00,481 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:56:00,568 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:56:00,588 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 05:56:00,591 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 05:56:00,609 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:56:00,615 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:56:00,751 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:56:00,756 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:56:00,780 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:56:00,790 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:00,791 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:56:00,815 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:56:00,829 INFO org.apache.hadoop.mapred.Task: Task:attempt_local303384604_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:56:00,845 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:00,847 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local303384604_0001_m_000000_0' done.
2016-01-05 05:56:00,847 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local303384604_0001_m_000000_0
2016-01-05 05:56:00,848 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:56:00,856 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:56:00,871 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5a20f443
2016-01-05 05:56:00,872 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:00,881 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:56:00,917 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:56:00,920 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:00,949 INFO org.apache.hadoop.mapred.Task: Task:attempt_local303384604_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:56:00,949 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:00,949 INFO org.apache.hadoop.mapred.Task: Task attempt_local303384604_0001_r_000000_0 is allowed to commit now
2016-01-05 05:56:00,951 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local303384604_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 05:56:00,952 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:56:00,952 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local303384604_0001_r_000000_0' done.
2016-01-05 05:56:01,344 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:56:01,347 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local303384604_0001
2016-01-05 05:56:01,359 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:56:01,361 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:56:01,364 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2708
2016-01-05 05:56:01,365 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181646
2016-01-05 05:56:01,365 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:56:01,365 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:56:01,366 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:56:01,366 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:56:01,366 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:56:01,366 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:56:01,367 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:56:01,367 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 05:56:01,367 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:56:01,369 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:56:01,370 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:56:01,373 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:56:01,374 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:56:01,376 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:56:01,376 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:56:01,377 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:56:01,377 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:56:01,377 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:56:01,377 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:56:01,377 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:56:01,378 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:56:01,489 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:56:01,492 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:56:01,497 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:56:01,512 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:56:01,709 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local321566425_0002
2016-01-05 05:56:01,710 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:56:01,710 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:56:01,716 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:56:01,717 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local321566425_0002_m_000000_0
2016-01-05 05:56:01,717 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:56:01,722 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@77546dbc
2016-01-05 05:56:01,724 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_1/part-r-00000:0+493
2016-01-05 05:56:01,724 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:56:01,731 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:56:01,834 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:56:01,840 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:56:01,860 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:01,874 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:56:01,879 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:56:01,883 INFO org.apache.hadoop.mapred.Task: Task:attempt_local321566425_0002_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:56:01,886 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:01,887 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local321566425_0002_m_000000_0' done.
2016-01-05 05:56:01,890 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local321566425_0002_m_000000_0
2016-01-05 05:56:01,890 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:56:01,890 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:56:01,904 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@1408a92
2016-01-05 05:56:01,905 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:01,906 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:56:01,910 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:56:01,911 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:01,940 INFO org.apache.hadoop.mapred.Task: Task:attempt_local321566425_0002_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:56:01,940 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:01,942 INFO org.apache.hadoop.mapred.Task: Task attempt_local321566425_0002_r_000000_0 is allowed to commit now
2016-01-05 05:56:01,946 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local321566425_0002_r_000000_0' to files/clustering/depth_2
2016-01-05 05:56:01,948 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:56:01,948 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local321566425_0002_r_000000_0' done.
2016-01-05 05:56:02,710 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:56:02,710 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local321566425_0002
2016-01-05 05:56:02,712 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:56:02,712 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:56:02,712 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=5306
2016-01-05 05:56:02,712 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=362516
2016-01-05 05:56:02,712 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:56:02,712 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:56:02,712 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:56:02,712 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:56:02,712 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:56:02,712 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:56:02,713 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:56:02,745 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:56:02,746 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:56:02,747 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:56:02,749 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:56:02,928 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1932130084_0003
2016-01-05 05:56:02,928 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:56:02,929 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:56:02,931 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:56:02,931 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1932130084_0003_m_000000_0
2016-01-05 05:56:02,931 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:56:02,932 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@359ecd80
2016-01-05 05:56:02,933 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_2/part-r-00000:0+493
2016-01-05 05:56:02,933 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:56:02,934 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:56:03,006 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:56:03,007 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:56:03,021 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:03,021 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:56:03,024 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:56:03,026 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1932130084_0003_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:56:03,027 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:03,027 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1932130084_0003_m_000000_0' done.
2016-01-05 05:56:03,027 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1932130084_0003_m_000000_0
2016-01-05 05:56:03,027 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:56:03,028 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:56:03,034 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@a98ce7e
2016-01-05 05:56:03,034 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:03,035 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:56:03,035 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:56:03,035 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:03,041 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1932130084_0003_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:56:03,041 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:56:03,041 INFO org.apache.hadoop.mapred.Task: Task attempt_local1932130084_0003_r_000000_0 is allowed to commit now
2016-01-05 05:56:03,043 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1932130084_0003_r_000000_0' to files/clustering/depth_3
2016-01-05 05:56:03,043 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:56:03,043 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1932130084_0003_r_000000_0' done.
2016-01-05 05:56:03,929 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:56:03,929 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1932130084_0003
2016-01-05 05:56:03,932 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 05:56:03,932 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:56:03,932 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=7904
2016-01-05 05:56:03,932 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=543394
2016-01-05 05:56:03,932 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:56:03,933 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:56:03,933 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:56:03,933 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:56:03,933 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:56:03,933 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:56:03,933 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:56:03,933 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:56:03,933 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:56:03,933 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:56:03,934 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:56:03,934 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:56:03,934 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:56:03,934 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:56:03,934 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:56:03,934 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:56:03,934 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:56:03,934 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:56:03,934 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=440270848
2016-01-05 05:56:03,937 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:56:03,937 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 05:56:03,937 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 05:56:03,937 INFO Kmeans.KMeansClusteringJob: SHAY3
2016-01-05 05:56:03,938 INFO Kmeans.KMeansClusteringJob: FOUND hdfs://0.0.0.0/user/cloudera/files/clustering/depth_3/part-r-00000
2016-01-05 05:56:03,938 INFO Kmeans.KMeansClusteringJob: SHAY4
2016-01-05 05:57:22,103 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:57:22,109 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:57:22,146 INFO Kmeans.KMeansClusteringJob: SHAY5
2016-01-05 05:57:22,149 INFO Kmeans.KMeansClusteringJob: SHAY6
2016-01-05 05:57:22,154 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 05:57:22,155 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 05:57:22,341 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:57:22,535 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:57:22,536 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:57:22,574 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:57:22,599 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:57:22,632 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:57:23,328 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:57:23,329 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local270908231_0001
2016-01-05 05:57:23,339 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:57:23,378 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:57:23,384 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local270908231_0001_m_000000_0
2016-01-05 05:57:23,457 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:57:23,559 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:57:23,617 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 05:57:23,621 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 05:57:23,627 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:57:23,629 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:57:23,719 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:57:23,720 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:57:23,728 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:57:23,730 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:23,730 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:57:23,739 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:57:23,743 INFO org.apache.hadoop.mapred.Task: Task:attempt_local270908231_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:57:23,748 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:23,748 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local270908231_0001_m_000000_0' done.
2016-01-05 05:57:23,748 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local270908231_0001_m_000000_0
2016-01-05 05:57:23,749 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:57:23,752 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:57:23,768 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5a20f443
2016-01-05 05:57:23,768 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:23,776 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:57:23,791 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:57:23,791 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:23,805 INFO org.apache.hadoop.mapred.Task: Task:attempt_local270908231_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:57:23,805 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:23,805 INFO org.apache.hadoop.mapred.Task: Task attempt_local270908231_0001_r_000000_0 is allowed to commit now
2016-01-05 05:57:23,808 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local270908231_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 05:57:23,809 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:57:23,809 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local270908231_0001_r_000000_0' done.
2016-01-05 05:57:24,333 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:57:24,334 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local270908231_0001
2016-01-05 05:57:24,344 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:57:24,345 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:57:24,345 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2708
2016-01-05 05:57:24,345 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181646
2016-01-05 05:57:24,345 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:57:24,345 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:57:24,345 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:57:24,345 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:57:24,345 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:57:24,345 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:57:24,346 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:57:24,346 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 05:57:24,346 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:57:24,346 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:57:24,346 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:57:24,346 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:57:24,346 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:57:24,346 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:57:24,346 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:57:24,347 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:57:24,347 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:57:24,347 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:57:24,347 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:57:24,347 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:57:24,347 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:57:24,418 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:57:24,422 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:57:24,428 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:57:24,433 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:57:24,627 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local60381373_0002
2016-01-05 05:57:24,627 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:57:24,628 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:57:24,639 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:57:24,639 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local60381373_0002_m_000000_0
2016-01-05 05:57:24,643 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:57:24,654 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@1664023c
2016-01-05 05:57:24,656 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_1/part-r-00000:0+493
2016-01-05 05:57:24,657 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:57:24,661 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:57:24,788 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:57:24,788 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:57:24,808 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:24,808 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:57:24,812 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:57:24,818 INFO org.apache.hadoop.mapred.Task: Task:attempt_local60381373_0002_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:57:24,827 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:24,828 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local60381373_0002_m_000000_0' done.
2016-01-05 05:57:24,828 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local60381373_0002_m_000000_0
2016-01-05 05:57:24,828 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:57:24,828 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:57:24,837 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@435db13f
2016-01-05 05:57:24,837 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:24,838 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:57:24,852 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:57:24,852 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:24,876 INFO org.apache.hadoop.mapred.Task: Task:attempt_local60381373_0002_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:57:24,880 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:24,882 INFO org.apache.hadoop.mapred.Task: Task attempt_local60381373_0002_r_000000_0 is allowed to commit now
2016-01-05 05:57:24,884 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local60381373_0002_r_000000_0' to files/clustering/depth_2
2016-01-05 05:57:24,888 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:57:24,888 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local60381373_0002_r_000000_0' done.
2016-01-05 05:57:25,627 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:57:25,628 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local60381373_0002
2016-01-05 05:57:25,630 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:57:25,630 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:57:25,630 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=5306
2016-01-05 05:57:25,630 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=362508
2016-01-05 05:57:25,630 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:57:25,630 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:57:25,630 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:57:25,630 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:57:25,630 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:57:25,631 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:57:25,667 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:57:25,668 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:57:25,669 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:57:25,671 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:57:25,747 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local543388893_0003
2016-01-05 05:57:25,752 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:57:25,753 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:57:25,760 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:57:25,761 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local543388893_0003_m_000000_0
2016-01-05 05:57:25,761 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:57:25,762 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@359ecd80
2016-01-05 05:57:25,765 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_2/part-r-00000:0+493
2016-01-05 05:57:25,768 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:57:25,768 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:57:25,832 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:57:25,834 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:57:25,856 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:25,857 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:57:25,858 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:57:25,860 INFO org.apache.hadoop.mapred.Task: Task:attempt_local543388893_0003_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:57:25,861 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:25,861 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local543388893_0003_m_000000_0' done.
2016-01-05 05:57:25,861 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local543388893_0003_m_000000_0
2016-01-05 05:57:25,861 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:57:25,861 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:57:25,869 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@1167e3a5
2016-01-05 05:57:25,869 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:25,871 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:57:25,871 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:57:25,871 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:25,878 INFO org.apache.hadoop.mapred.Task: Task:attempt_local543388893_0003_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:57:25,878 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:57:25,878 INFO org.apache.hadoop.mapred.Task: Task attempt_local543388893_0003_r_000000_0 is allowed to commit now
2016-01-05 05:57:25,880 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local543388893_0003_r_000000_0' to files/clustering/depth_3
2016-01-05 05:57:25,880 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:57:25,880 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local543388893_0003_r_000000_0' done.
2016-01-05 05:57:26,748 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:57:26,748 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local543388893_0003
2016-01-05 05:57:26,751 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 05:57:26,751 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:57:26,751 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=7904
2016-01-05 05:57:26,751 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=543378
2016-01-05 05:57:26,751 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:57:26,751 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:57:26,751 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:57:26,752 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:57:26,752 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:57:26,752 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:57:26,752 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:57:26,752 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:57:26,752 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:57:26,752 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:57:26,752 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:57:26,752 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:57:26,753 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:57:26,753 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:57:26,753 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:57:26,753 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:57:26,753 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:57:26,753 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:57:26,753 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=440270848
2016-01-05 05:57:26,755 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:57:26,756 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 05:57:26,756 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 05:59:19,767 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 05:59:19,775 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:59:19,809 INFO Kmeans.KMeansClusteringJob: SHAY5
2016-01-05 05:59:19,810 INFO Kmeans.KMeansClusteringJob: SHAY6
2016-01-05 05:59:19,812 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 05:59:19,815 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 05:59:19,983 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 05:59:20,153 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 05:59:20,159 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 05:59:20,206 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:59:20,225 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:59:20,252 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:59:21,048 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:59:21,049 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local198898733_0001
2016-01-05 05:59:21,065 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:59:21,118 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:59:21,119 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local198898733_0001_m_000000_0
2016-01-05 05:59:21,156 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:59:21,227 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 05:59:21,243 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 05:59:21,245 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 05:59:21,255 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:59:21,257 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:59:21,342 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:59:21,342 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:59:21,350 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 05:59:21,352 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:21,352 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:59:21,373 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:59:21,378 INFO org.apache.hadoop.mapred.Task: Task:attempt_local198898733_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:59:21,383 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:21,384 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local198898733_0001_m_000000_0' done.
2016-01-05 05:59:21,384 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local198898733_0001_m_000000_0
2016-01-05 05:59:21,384 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:59:21,388 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:59:21,393 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5a20f443
2016-01-05 05:59:21,394 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:21,399 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:59:21,409 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:59:21,409 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:21,431 INFO org.apache.hadoop.mapred.Task: Task:attempt_local198898733_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:59:21,432 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:21,433 INFO org.apache.hadoop.mapred.Task: Task attempt_local198898733_0001_r_000000_0 is allowed to commit now
2016-01-05 05:59:21,438 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local198898733_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 05:59:21,439 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:59:21,439 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local198898733_0001_r_000000_0' done.
2016-01-05 05:59:22,057 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:59:22,058 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local198898733_0001
2016-01-05 05:59:22,065 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:59:22,066 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:59:22,066 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2708
2016-01-05 05:59:22,066 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181646
2016-01-05 05:59:22,066 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:59:22,066 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:59:22,066 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:59:22,067 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:59:22,067 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:59:22,067 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:59:22,067 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:59:22,067 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 05:59:22,067 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:59:22,067 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:59:22,067 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:59:22,067 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:59:22,068 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:59:22,068 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:59:22,068 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:59:22,068 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:59:22,068 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:59:22,068 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:59:22,068 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:59:22,068 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:59:22,068 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:59:22,145 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:59:22,147 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:59:22,151 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:59:22,159 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:59:22,348 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local2111866938_0002
2016-01-05 05:59:22,348 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:59:22,349 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:59:22,361 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:59:22,362 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2111866938_0002_m_000000_0
2016-01-05 05:59:22,363 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:59:22,369 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@7fcebc9f
2016-01-05 05:59:22,372 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_1/part-r-00000:0+493
2016-01-05 05:59:22,372 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:59:22,375 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:59:22,497 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:59:22,500 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:59:22,520 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:22,521 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:59:22,522 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:59:22,528 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2111866938_0002_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:59:22,533 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:22,534 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2111866938_0002_m_000000_0' done.
2016-01-05 05:59:22,534 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2111866938_0002_m_000000_0
2016-01-05 05:59:22,534 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:59:22,534 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:59:22,542 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@3c1fc1a6
2016-01-05 05:59:22,543 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:22,543 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:59:22,556 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:59:22,557 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:22,588 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2111866938_0002_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:59:22,588 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:22,591 INFO org.apache.hadoop.mapred.Task: Task attempt_local2111866938_0002_r_000000_0 is allowed to commit now
2016-01-05 05:59:22,594 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2111866938_0002_r_000000_0' to files/clustering/depth_2
2016-01-05 05:59:22,597 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:59:22,597 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2111866938_0002_r_000000_0' done.
2016-01-05 05:59:23,349 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:59:23,349 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local2111866938_0002
2016-01-05 05:59:23,351 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 05:59:23,351 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:59:23,351 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=5306
2016-01-05 05:59:23,351 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=362524
2016-01-05 05:59:23,351 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:59:23,351 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:59:23,351 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:59:23,351 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:59:23,352 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:59:23,353 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:59:23,355 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:59:23,355 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:59:23,355 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:59:23,355 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:59:23,355 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:59:23,355 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:59:23,355 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:59:23,355 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:59:23,356 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:59:23,356 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:59:23,356 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:59:23,356 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:59:23,356 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 05:59:23,356 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 05:59:23,356 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 05:59:23,388 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 05:59:23,389 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 05:59:23,390 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 05:59:23,392 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 05:59:23,464 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1678004558_0003
2016-01-05 05:59:23,464 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 05:59:23,465 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 05:59:23,467 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 05:59:23,467 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1678004558_0003_m_000000_0
2016-01-05 05:59:23,467 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:59:23,468 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@4cc5aa00
2016-01-05 05:59:23,476 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_2/part-r-00000:0+493
2016-01-05 05:59:23,476 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 05:59:23,476 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 05:59:23,545 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 05:59:23,545 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 05:59:23,566 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:23,568 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 05:59:23,570 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 05:59:23,578 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1678004558_0003_m_000000_0 is done. And is in the process of commiting
2016-01-05 05:59:23,579 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:23,580 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1678004558_0003_m_000000_0' done.
2016-01-05 05:59:23,580 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1678004558_0003_m_000000_0
2016-01-05 05:59:23,580 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 05:59:23,580 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 05:59:23,587 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@3b926e90
2016-01-05 05:59:23,588 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:23,589 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 05:59:23,589 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 05:59:23,589 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:23,594 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1678004558_0003_r_000000_0 is done. And is in the process of commiting
2016-01-05 05:59:23,594 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 05:59:23,594 INFO org.apache.hadoop.mapred.Task: Task attempt_local1678004558_0003_r_000000_0 is allowed to commit now
2016-01-05 05:59:23,596 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1678004558_0003_r_000000_0' to files/clustering/depth_3
2016-01-05 05:59:23,596 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 05:59:23,596 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1678004558_0003_r_000000_0' done.
2016-01-05 05:59:24,465 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 05:59:24,465 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1678004558_0003
2016-01-05 05:59:24,468 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 05:59:24,469 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 05:59:24,469 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=7904
2016-01-05 05:59:24,469 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=543402
2016-01-05 05:59:24,469 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 05:59:24,469 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 05:59:24,469 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 05:59:24,469 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 05:59:24,469 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 05:59:24,469 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 05:59:24,469 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 05:59:24,469 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 05:59:24,469 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 05:59:24,470 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 05:59:24,470 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 05:59:24,470 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 05:59:24,470 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 05:59:24,470 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 05:59:24,471 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 05:59:24,471 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 05:59:24,471 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 05:59:24,471 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 05:59:24,471 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=440270848
2016-01-05 05:59:24,473 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 05:59:24,473 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 05:59:24,473 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:04:20,387 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:04:20,390 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:04:20,443 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 06:04:20,443 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 06:04:20,709 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:04:20,964 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:04:20,965 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:04:21,221 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:04:21,247 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:04:21,255 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:04:21,949 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local489996427_0001
2016-01-05 06:04:21,954 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:04:21,963 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:04:21,995 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:04:21,996 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local489996427_0001_m_000000_0
2016-01-05 06:04:22,052 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:04:22,213 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:04:22,257 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@3219762f
2016-01-05 06:04:22,259 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 06:04:22,271 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:04:22,274 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:04:23,290 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:04:23,327 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:04:23,426 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 06:04:23,625 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:04:23,645 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:04:23,645 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:04:23,891 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:04:23,894 INFO org.apache.hadoop.mapred.Task: Task:attempt_local489996427_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:04:23,947 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:04:23,947 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local489996427_0001_m_000000_0' done.
2016-01-05 06:04:23,947 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local489996427_0001_m_000000_0
2016-01-05 06:04:23,947 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:04:23,958 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:04:23,986 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@54671f95
2016-01-05 06:04:23,986 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:04:24,008 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:04:24,215 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:04:24,216 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:04:24,315 INFO org.apache.hadoop.mapred.Task: Task:attempt_local489996427_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:04:24,320 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:04:24,320 INFO org.apache.hadoop.mapred.Task: Task attempt_local489996427_0001_r_000000_0 is allowed to commit now
2016-01-05 06:04:24,335 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local489996427_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:04:24,335 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:04:24,335 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local489996427_0001_r_000000_0' done.
2016-01-05 06:04:24,558 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:04:24,559 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local489996427_0001
2016-01-05 06:04:24,607 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 06:04:24,607 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:04:24,607 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2708
2016-01-05 06:04:24,607 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181646
2016-01-05 06:04:24,607 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:04:24,607 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:04:24,608 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:04:24,608 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:04:24,608 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:04:24,608 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:04:24,608 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:04:24,608 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 06:04:24,608 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:04:24,608 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:04:24,608 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:04:24,609 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:04:24,609 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:04:24,609 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:04:24,609 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:04:24,609 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:04:24,609 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:04:24,609 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:04:24,609 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:04:24,609 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 06:04:24,609 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 06:04:24,801 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 06:04:25,009 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:04:25,010 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:04:25,012 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:04:25,243 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1373423215_0002
2016-01-05 06:04:25,243 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:04:25,244 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:04:25,246 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:04:25,247 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1373423215_0002_m_000000_0
2016-01-05 06:04:25,247 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:04:25,248 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@48e29820
2016-01-05 06:04:25,255 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_1/part-r-00000:0+493
2016-01-05 06:04:25,255 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:04:25,256 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:04:25,353 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:04:25,354 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:04:25,376 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:04:25,380 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:04:25,409 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:04:25,410 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1373423215_0002_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:04:25,411 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:04:25,411 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1373423215_0002_m_000000_0' done.
2016-01-05 06:04:25,411 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1373423215_0002_m_000000_0
2016-01-05 06:04:25,414 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:04:25,415 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:04:25,420 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@6536d9d8
2016-01-05 06:04:25,420 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:04:25,421 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:04:25,424 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:04:25,425 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:04:25,444 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1373423215_0002_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:04:25,446 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:04:25,468 INFO org.apache.hadoop.mapred.Task: Task attempt_local1373423215_0002_r_000000_0 is allowed to commit now
2016-01-05 06:04:25,474 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1373423215_0002_r_000000_0' to files/clustering/depth_2
2016-01-05 06:04:25,475 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:04:25,475 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1373423215_0002_r_000000_0' done.
2016-01-05 06:04:26,244 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:04:26,244 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1373423215_0002
2016-01-05 06:04:26,245 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 06:04:26,266 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:04:26,266 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=5306
2016-01-05 06:04:26,266 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=362524
2016-01-05 06:04:26,266 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:04:26,267 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:04:26,268 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:04:26,268 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:04:26,268 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:04:26,268 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:04:26,270 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:04:26,271 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 06:04:26,271 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:04:26,271 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:04:26,271 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:04:26,271 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:04:26,271 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:04:26,271 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:04:26,271 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:04:26,272 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:04:26,272 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:04:26,272 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:04:26,272 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:04:26,272 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 06:04:26,272 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 06:07:09,105 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:07:09,111 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:07:09,405 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:07:09,426 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:07:09,444 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:07:09,996 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1453597465_0001
2016-01-05 06:07:09,998 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:07:10,006 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:07:10,075 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:07:10,076 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1453597465_0001_m_000000_0
2016-01-05 06:07:10,105 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:07:10,143 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:07:10,167 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@59c208b0
2016-01-05 06:07:10,170 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/Input/CanopyVectors:0+56
2016-01-05 06:07:10,175 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:07:10,178 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:07:10,466 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:07:10,466 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:07:10,569 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:07:10,569 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:07:10,774 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:07:10,775 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1453597465_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:07:10,809 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:07:10,809 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1453597465_0001_m_000000_0' done.
2016-01-05 06:07:10,809 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1453597465_0001_m_000000_0
2016-01-05 06:07:10,809 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:07:10,831 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:07:10,839 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5e29c58e
2016-01-05 06:07:10,839 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:07:10,850 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:07:10,951 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 158 bytes
2016-01-05 06:07:10,951 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:07:11,009 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 0%
2016-01-05 06:07:11,375 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1453597465_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:07:11,376 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:07:11,376 INFO org.apache.hadoop.mapred.Task: Task attempt_local1453597465_0001_r_000000_0 is allowed to commit now
2016-01-05 06:07:11,379 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1453597465_0001_r_000000_0' to /home/training/Desktop/Canopy/output
2016-01-05 06:07:11,379 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:07:11,379 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1453597465_0001_r_000000_0' done.
2016-01-05 06:07:12,019 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:07:12,019 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1453597465_0001
2016-01-05 06:07:12,023 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:07:12,024 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:07:12,024 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=620
2016-01-05 06:07:12,024 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=177510
2016-01-05 06:07:12,024 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:07:12,024 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:07:12,024 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:07:12,024 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:07:12,025 INFO org.apache.hadoop.mapred.JobClient:     Map input records=14
2016-01-05 06:07:12,025 INFO org.apache.hadoop.mapred.JobClient:     Map output records=6
2016-01-05 06:07:12,025 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=144
2016-01-05 06:07:12,025 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 06:07:12,025 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:07:12,025 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:07:12,025 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:07:12,025 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:07:12,025 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=6
2016-01-05 06:07:12,026 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=2
2016-01-05 06:07:12,026 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=12
2016-01-05 06:07:12,026 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:07:12,026 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:07:12,026 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:07:12,026 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:07:32,533 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.0, 4.0]]] / 2
2016-01-05 06:07:32,536 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[6.0, 5.0]]] / 4
2016-01-05 06:07:32,847 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:07:32,873 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:07:33,231 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:07:33,235 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:07:33,750 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:07:33,755 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:07:33,763 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:07:34,577 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local127788399_0001
2016-01-05 06:07:34,580 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:07:34,585 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:07:34,626 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:07:34,628 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local127788399_0001_m_000000_0
2016-01-05 06:07:34,647 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:07:34,795 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:07:34,890 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@50502819
2016-01-05 06:07:34,893 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 06:07:34,929 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:07:34,936 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:09:35,856 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:09:35,905 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:09:36,064 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.0, 1.0]]] / 1
2016-01-05 06:09:36,065 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[5.0, 5.0]]] / 1
2016-01-05 06:09:36,461 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:09:37,602 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:09:37,647 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:09:38,772 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:09:38,794 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:09:38,804 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:11:22,801 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:11:22,827 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:11:22,859 WARN org.apache.hadoop.fs.FSInputChecker: Problem opening checksum file: file:/home/training/Desktop/Canopy/output/part-r-00000.  Ignoring exception: 
java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:147)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:334)
	at org.apache.hadoop.io.SequenceFile$Reader.openFile(SequenceFile.java:1787)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1707)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at Kmeans.KMeansClusteringJob.main(KMeansClusteringJob.java:64)
2016-01-05 06:12:02,517 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:12:02,527 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:12:02,759 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:12:02,761 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:12:03,263 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:12:03,289 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:12:03,298 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:12:03,790 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1382137_0001
2016-01-05 06:12:03,791 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:12:03,844 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:12:03,927 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:12:03,928 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1382137_0001_m_000000_0
2016-01-05 06:12:04,006 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:12:04,169 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:12:04,200 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@67ce85c4
2016-01-05 06:12:04,205 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 06:12:04,238 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:12:04,248 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:12:04,508 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:12:04,513 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:12:04,685 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:12:04,696 WARN org.apache.hadoop.fs.FSInputChecker: Problem opening checksum file: file:/home/training/Desktop/Canopy/output/part-r-00000.  Ignoring exception: 
java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:147)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:334)
	at org.apache.hadoop.io.SequenceFile$Reader.openFile(SequenceFile.java:1787)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1707)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at Kmeans.KMeansMapper.setup(KMeansMapper.java:32)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:138)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 06:12:04,716 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:12:04,716 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1382137_0001
java.lang.Exception: java.io.EOFException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1800)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1765)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1714)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at Kmeans.KMeansMapper.setup(KMeansMapper.java:32)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:138)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 06:12:04,815 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 06:12:04,816 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1382137_0001
2016-01-05 06:12:04,816 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 06:12:04,831 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:12:41,084 WARN org.apache.hadoop.fs.FSInputChecker: Problem opening checksum file: file:/home/training/Desktop/Canopy/output/part-r-00000.  Ignoring exception: 
java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:180)
	at java.io.DataInputStream.readFully(DataInputStream.java:152)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:147)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:334)
	at org.apache.hadoop.io.SequenceFile$Reader.openFile(SequenceFile.java:1787)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1707)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1728)
	at Kmeans.KMeansClusteringJob.main(KMeansClusteringJob.java:39)
2016-01-05 06:13:58,616 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:13:58,623 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:13:58,935 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:13:58,952 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:13:58,967 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training858036272/.staging/job_local858036272_0001
2016-01-05 06:13:58,968 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/training/Desktop/Canopy/CanopyVectors
2016-01-05 06:14:19,047 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:14:19,090 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:14:19,603 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:14:19,626 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:14:19,650 INFO org.apache.hadoop.mapred.JobClient: Cleaning up the staging area file:/tmp/hadoop-training/mapred/staging/training948925570/.staging/job_local948925570_0001
2016-01-05 06:14:19,651 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:training (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/training/Desktop/Canopy/CanopyVectors
2016-01-05 06:15:10,682 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:15:10,689 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:15:10,921 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:15:10,938 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:15:10,965 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:15:11,572 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local757923459_0001
2016-01-05 06:15:11,576 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:15:11,580 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:15:11,634 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:15:11,635 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local757923459_0001_m_000000_0
2016-01-05 06:15:11,687 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:15:11,788 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:15:11,840 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@59c208b0
2016-01-05 06:15:11,845 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Canopy/Input/CanopyVectors:0+56
2016-01-05 06:15:11,858 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:15:11,877 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:15:11,979 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:15:11,979 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:15:12,057 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:12,057 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:15:12,190 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:15:12,192 INFO org.apache.hadoop.mapred.Task: Task:attempt_local757923459_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:15:12,208 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:12,209 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local757923459_0001_m_000000_0' done.
2016-01-05 06:15:12,209 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local757923459_0001_m_000000_0
2016-01-05 06:15:12,219 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:15:12,234 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:15:12,240 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@3a51127a
2016-01-05 06:15:12,241 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:12,248 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:15:12,378 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 158 bytes
2016-01-05 06:15:12,378 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:12,459 INFO org.apache.hadoop.mapred.Task: Task:attempt_local757923459_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:15:12,460 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:12,460 INFO org.apache.hadoop.mapred.Task: Task attempt_local757923459_0001_r_000000_0 is allowed to commit now
2016-01-05 06:15:12,461 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local757923459_0001_r_000000_0' to /home/training/Desktop/Canopy/output
2016-01-05 06:15:12,462 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:15:12,462 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local757923459_0001_r_000000_0' done.
2016-01-05 06:15:12,593 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:15:12,594 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local757923459_0001
2016-01-05 06:15:12,599 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:15:12,599 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:15:12,599 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=620
2016-01-05 06:15:12,599 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=177502
2016-01-05 06:15:12,599 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:15:12,599 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:15:12,599 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:15:12,599 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:15:12,600 INFO org.apache.hadoop.mapred.JobClient:     Map input records=14
2016-01-05 06:15:12,600 INFO org.apache.hadoop.mapred.JobClient:     Map output records=6
2016-01-05 06:15:12,600 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=144
2016-01-05 06:15:12,600 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 06:15:12,600 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:15:12,600 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:15:12,600 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:15:12,600 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:15:12,601 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=6
2016-01-05 06:15:12,601 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=2
2016-01-05 06:15:12,601 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=12
2016-01-05 06:15:12,601 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:15:12,601 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:15:12,601 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:15:12,601 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:15:47,764 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.0, 4.0]]] / 2
2016-01-05 06:15:47,765 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[6.0, 5.0]]] / 4
2016-01-05 06:15:48,191 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:15:48,199 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:15:48,437 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:15:48,439 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:15:48,536 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:15:48,555 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:15:48,597 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:15:49,173 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1057850292_0001
2016-01-05 06:15:49,177 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:15:49,181 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:15:49,215 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:15:49,216 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1057850292_0001_m_000000_0
2016-01-05 06:15:49,238 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:15:49,308 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:15:49,330 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@bdccedd
2016-01-05 06:15:49,332 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 06:15:49,351 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:15:49,353 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:15:49,691 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:15:49,695 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:15:49,936 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:15:49,989 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:50,040 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:15:50,248 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 06:15:50,339 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:15:50,340 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1057850292_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:15:50,435 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:50,436 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1057850292_0001_m_000000_0' done.
2016-01-05 06:15:50,436 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1057850292_0001_m_000000_0
2016-01-05 06:15:50,436 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:15:50,440 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:15:50,449 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@2ed7b7d9
2016-01-05 06:15:50,450 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:50,498 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:15:50,980 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:15:50,981 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:50,993 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1057850292_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:15:50,993 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:50,994 INFO org.apache.hadoop.mapred.Task: Task attempt_local1057850292_0001_r_000000_0 is allowed to commit now
2016-01-05 06:15:50,995 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1057850292_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:15:50,996 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:15:50,996 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1057850292_0001_r_000000_0' done.
2016-01-05 06:15:51,249 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:15:51,250 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1057850292_0001
2016-01-05 06:15:51,271 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 06:15:51,272 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:15:51,272 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2472
2016-01-05 06:15:51,272 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181224
2016-01-05 06:15:51,272 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:15:51,272 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:15:51,272 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:15:51,272 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:15:51,272 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:15:51,273 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:15:51,273 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:15:51,273 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 06:15:51,273 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:15:51,273 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:15:51,273 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:15:51,273 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:15:51,273 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:15:51,273 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:15:51,273 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:15:51,274 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:15:51,274 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:15:51,274 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:15:51,274 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:15:51,274 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 06:15:51,274 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=1
2016-01-05 06:15:51,420 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 06:15:51,422 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:15:51,424 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:15:51,448 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:15:51,654 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local777273588_0002
2016-01-05 06:15:51,655 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:15:51,657 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:15:51,760 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:15:51,764 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local777273588_0002_m_000000_0
2016-01-05 06:15:51,764 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:15:51,770 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@435db13f
2016-01-05 06:15:51,773 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_1/part-r-00000:0+493
2016-01-05 06:15:51,774 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:15:51,774 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:15:52,057 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:15:52,062 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:15:52,103 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:52,106 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:15:52,113 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:15:52,117 INFO org.apache.hadoop.mapred.Task: Task:attempt_local777273588_0002_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:15:52,122 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:52,124 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local777273588_0002_m_000000_0' done.
2016-01-05 06:15:52,125 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local777273588_0002_m_000000_0
2016-01-05 06:15:52,126 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:15:52,126 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:15:52,131 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@319c0bd6
2016-01-05 06:15:52,133 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:52,134 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:15:52,139 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:15:52,139 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:52,152 INFO org.apache.hadoop.mapred.Task: Task:attempt_local777273588_0002_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:15:52,153 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:15:52,153 INFO org.apache.hadoop.mapred.Task: Task attempt_local777273588_0002_r_000000_0 is allowed to commit now
2016-01-05 06:15:52,154 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local777273588_0002_r_000000_0' to files/clustering/depth_2
2016-01-05 06:15:52,155 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:15:52,155 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local777273588_0002_r_000000_0' done.
2016-01-05 06:15:52,655 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:15:52,655 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local777273588_0002
2016-01-05 06:15:52,657 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:15:52,657 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:15:52,657 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=5070
2016-01-05 06:15:52,657 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=362094
2016-01-05 06:15:52,657 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:15:52,657 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:15:52,657 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:15:52,657 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:15:52,657 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:15:52,657 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:15:52,657 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:15:52,657 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 06:15:52,658 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:15:52,658 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:15:52,658 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:15:52,658 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:15:52,658 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:15:52,658 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:15:52,658 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:15:52,658 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:15:52,658 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:15:52,658 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:15:52,658 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:15:52,661 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:15:52,661 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:15:52,661 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:24:06,885 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:24:06,903 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:24:06,977 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 06:24:06,977 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 06:24:07,239 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:24:07,509 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:24:07,517 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:24:07,733 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:24:07,745 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:24:07,777 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:24:08,325 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:24:08,326 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local902114898_0001
2016-01-05 06:24:08,334 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:24:08,357 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:24:08,358 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local902114898_0001_m_000000_0
2016-01-05 06:24:08,389 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:24:08,434 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:24:08,451 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@259e215b
2016-01-05 06:24:08,453 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+104
2016-01-05 06:24:08,458 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:24:08,460 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:24:08,643 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:24:08,643 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:24:08,875 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:24:08,876 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:24:08,876 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:24:09,020 INFO org.apache.hadoop.mapred.Task: Task:attempt_local902114898_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:24:09,054 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:24:09,054 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local902114898_0001_m_000000_0' done.
2016-01-05 06:24:09,054 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local902114898_0001_m_000000_0
2016-01-05 06:24:09,054 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:24:09,061 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:24:09,066 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@1b0deb5f
2016-01-05 06:24:09,066 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:24:09,071 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:24:09,165 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-01-05 06:24:09,165 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:24:09,198 INFO org.apache.hadoop.mapred.Task: Task:attempt_local902114898_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:24:09,199 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:24:09,199 INFO org.apache.hadoop.mapred.Task: Task attempt_local902114898_0001_r_000000_0 is allowed to commit now
2016-01-05 06:24:09,201 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local902114898_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:24:09,201 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:24:09,201 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local902114898_0001_r_000000_0' done.
2016-01-05 06:24:09,360 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 100%
2016-01-05 06:24:09,361 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local902114898_0001
2016-01-05 06:24:09,383 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:24:09,383 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:24:09,387 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=1498
2016-01-05 06:24:09,388 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=179084
2016-01-05 06:24:09,388 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:24:09,388 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:24:09,389 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:24:09,389 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:24:09,389 INFO org.apache.hadoop.mapred.JobClient:     Map input records=0
2016-01-05 06:24:09,389 INFO org.apache.hadoop.mapred.JobClient:     Map output records=0
2016-01-05 06:24:09,389 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=0
2016-01-05 06:24:09,389 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 06:24:09,389 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:24:09,389 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:24:09,390 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=0
2016-01-05 06:24:09,390 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:24:09,390 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=0
2016-01-05 06:24:09,390 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=0
2016-01-05 06:24:09,390 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=0
2016-01-05 06:24:09,390 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:24:09,390 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:24:09,390 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:24:09,390 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:24:09,411 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:24:09,415 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:24:09,415 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:25:24,209 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:25:24,224 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:25:24,559 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:25:24,810 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:25:24,817 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:25:25,036 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:25:25,046 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:25:25,055 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:25:25,545 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:25:25,546 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local340185688_0001
2016-01-05 06:25:25,560 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:25:25,592 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:25:25,592 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local340185688_0001_m_000000_0
2016-01-05 06:25:25,615 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:25:25,655 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:25:25,659 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@3219762f
2016-01-05 06:25:25,662 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+104
2016-01-05 06:25:25,669 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:25:25,671 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:25:25,773 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:25:25,773 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:25:25,783 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:25:25,783 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:25:25,783 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:25:25,850 INFO org.apache.hadoop.mapred.Task: Task:attempt_local340185688_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:25:25,858 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:25:25,858 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local340185688_0001_m_000000_0' done.
2016-01-05 06:25:25,859 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local340185688_0001_m_000000_0
2016-01-05 06:25:25,859 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:25:25,862 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:25:25,867 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5a20f443
2016-01-05 06:25:25,867 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:25:25,885 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:25:25,923 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-01-05 06:25:25,923 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:25:25,939 INFO org.apache.hadoop.mapred.Task: Task:attempt_local340185688_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:25:25,939 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:25:25,939 INFO org.apache.hadoop.mapred.Task: Task attempt_local340185688_0001_r_000000_0 is allowed to commit now
2016-01-05 06:25:25,942 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local340185688_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:25:25,943 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:25:25,945 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local340185688_0001_r_000000_0' done.
2016-01-05 06:25:26,561 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 100%
2016-01-05 06:25:26,563 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local340185688_0001
2016-01-05 06:25:26,568 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:25:26,568 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:25:26,568 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=1156
2016-01-05 06:25:26,568 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=179018
2016-01-05 06:25:26,568 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:25:26,568 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:25:26,568 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:25:26,568 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:25:26,569 INFO org.apache.hadoop.mapred.JobClient:     Map input records=0
2016-01-05 06:25:26,569 INFO org.apache.hadoop.mapred.JobClient:     Map output records=0
2016-01-05 06:25:26,569 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=0
2016-01-05 06:25:26,569 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 06:25:26,569 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:25:26,569 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:25:26,569 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=0
2016-01-05 06:25:26,569 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:25:26,569 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=0
2016-01-05 06:25:26,570 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=0
2016-01-05 06:25:26,570 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=0
2016-01-05 06:25:26,570 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:25:26,573 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:25:26,573 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:25:26,573 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:25:26,581 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:25:26,582 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:25:26,582 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:26:17,856 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:26:17,858 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:26:18,022 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:26:18,025 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:26:18,155 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:26:18,171 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:26:18,189 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:26:18,712 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1698245294_0001
2016-01-05 06:26:18,714 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:26:18,723 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:26:18,766 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:26:18,767 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1698245294_0001_m_000000_0
2016-01-05 06:26:18,854 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:26:19,076 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:26:19,146 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@3c1a1399
2016-01-05 06:26:19,160 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+104
2016-01-05 06:26:19,182 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:26:19,191 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:26:19,381 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:26:19,384 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:26:19,437 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:26:19,447 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:26:19,452 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:26:19,452 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:26:19,485 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1698245294_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:26:19,503 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:26:19,508 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1698245294_0001_m_000000_0' done.
2016-01-05 06:26:19,508 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1698245294_0001_m_000000_0
2016-01-05 06:26:19,508 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:26:19,512 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:26:19,547 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@6293df2c
2016-01-05 06:26:19,551 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:26:19,562 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:26:19,609 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-01-05 06:26:19,609 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:26:19,649 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1698245294_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:26:19,654 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:26:19,654 INFO org.apache.hadoop.mapred.Task: Task attempt_local1698245294_0001_r_000000_0 is allowed to commit now
2016-01-05 06:26:19,658 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1698245294_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:26:19,660 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:26:19,661 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1698245294_0001_r_000000_0' done.
2016-01-05 06:26:19,715 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 100%
2016-01-05 06:26:19,716 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1698245294_0001
2016-01-05 06:26:19,729 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:26:19,729 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:26:19,729 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=878
2016-01-05 06:26:19,731 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=179026
2016-01-05 06:26:19,731 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:26:19,732 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:26:19,732 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:26:19,732 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:26:19,732 INFO org.apache.hadoop.mapred.JobClient:     Map input records=0
2016-01-05 06:26:19,732 INFO org.apache.hadoop.mapred.JobClient:     Map output records=0
2016-01-05 06:26:19,732 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=0
2016-01-05 06:26:19,732 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 06:26:19,732 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:26:19,732 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:26:19,733 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=0
2016-01-05 06:26:19,736 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:26:19,736 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=0
2016-01-05 06:26:19,736 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=0
2016-01-05 06:26:19,738 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=0
2016-01-05 06:26:19,738 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:26:19,738 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:26:19,738 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:26:19,739 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:26:19,783 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:26:19,784 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:26:19,789 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:27:28,979 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:27:28,982 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:27:29,167 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:27:29,332 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:27:29,341 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:27:29,439 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:27:29,455 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:27:29,484 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:27:30,466 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:27:30,469 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local2026476507_0001
2016-01-05 06:27:30,481 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:27:30,494 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:27:30,494 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2026476507_0001_m_000000_0
2016-01-05 06:27:30,516 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:27:30,543 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:27:30,547 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@3219762f
2016-01-05 06:27:30,549 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+104
2016-01-05 06:27:30,554 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:27:30,556 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:27:30,649 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:27:30,650 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:27:30,657 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:27:30,657 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:27:30,658 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:27:30,679 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2026476507_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:27:30,684 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:27:30,684 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2026476507_0001_m_000000_0' done.
2016-01-05 06:27:30,684 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2026476507_0001_m_000000_0
2016-01-05 06:27:30,685 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:27:30,688 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:27:30,696 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5a20f443
2016-01-05 06:27:30,696 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:27:30,704 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:27:30,725 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-01-05 06:27:30,725 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:27:30,738 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2026476507_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:27:30,739 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:27:30,739 INFO org.apache.hadoop.mapred.Task: Task attempt_local2026476507_0001_r_000000_0 is allowed to commit now
2016-01-05 06:27:30,741 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local2026476507_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:27:30,741 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:27:30,741 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2026476507_0001_r_000000_0' done.
2016-01-05 06:27:31,479 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 100%
2016-01-05 06:27:31,481 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local2026476507_0001
2016-01-05 06:27:31,485 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:27:31,486 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:27:31,486 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=1124
2016-01-05 06:27:31,486 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=179026
2016-01-05 06:27:31,486 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:27:31,486 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:27:31,486 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:27:31,486 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:27:31,486 INFO org.apache.hadoop.mapred.JobClient:     Map input records=0
2016-01-05 06:27:31,487 INFO org.apache.hadoop.mapred.JobClient:     Map output records=0
2016-01-05 06:27:31,487 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=0
2016-01-05 06:27:31,487 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 06:27:31,487 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:27:31,487 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:27:31,487 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=0
2016-01-05 06:27:31,487 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:27:31,487 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=0
2016-01-05 06:27:31,487 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=0
2016-01-05 06:27:31,487 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=0
2016-01-05 06:27:31,488 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:27:31,488 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:27:31,488 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:27:31,491 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:27:31,498 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:27:31,499 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:27:31,499 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:28:14,283 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:28:14,291 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:28:14,500 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:28:14,679 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:28:14,684 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:28:14,728 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:28:14,747 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:28:14,780 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:28:15,417 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1705358622_0001
2016-01-05 06:28:15,421 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:28:15,429 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:28:15,467 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:28:15,468 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1705358622_0001_m_000000_0
2016-01-05 06:28:15,510 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:28:15,574 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:28:15,593 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 06:28:15,595 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+104
2016-01-05 06:28:15,621 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:28:15,628 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:28:15,845 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:28:15,845 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:28:15,853 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:28:15,853 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:28:15,853 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:28:15,862 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1705358622_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:28:15,867 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:28:15,868 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1705358622_0001_m_000000_0' done.
2016-01-05 06:28:15,868 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1705358622_0001_m_000000_0
2016-01-05 06:28:15,868 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:28:15,871 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:28:15,883 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@d24111a
2016-01-05 06:28:15,883 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:28:15,887 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:28:15,895 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-01-05 06:28:15,896 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:28:15,911 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1705358622_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:28:15,912 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:28:15,912 INFO org.apache.hadoop.mapred.Task: Task attempt_local1705358622_0001_r_000000_0 is allowed to commit now
2016-01-05 06:28:15,914 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1705358622_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:28:15,915 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:28:15,915 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1705358622_0001_r_000000_0' done.
2016-01-05 06:28:16,419 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 100%
2016-01-05 06:28:16,422 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1705358622_0001
2016-01-05 06:28:16,428 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:28:16,428 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:28:16,428 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=1146
2016-01-05 06:28:16,428 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=179092
2016-01-05 06:28:16,428 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:28:16,428 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:28:16,429 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:28:16,429 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:28:16,429 INFO org.apache.hadoop.mapred.JobClient:     Map input records=0
2016-01-05 06:28:16,432 INFO org.apache.hadoop.mapred.JobClient:     Map output records=0
2016-01-05 06:28:16,433 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=0
2016-01-05 06:28:16,433 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 06:28:16,433 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:28:16,433 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:28:16,433 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=0
2016-01-05 06:28:16,433 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:28:16,433 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=0
2016-01-05 06:28:16,433 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=0
2016-01-05 06:28:16,434 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=0
2016-01-05 06:28:16,434 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:28:16,434 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:28:16,434 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:28:16,434 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:28:16,441 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:28:16,442 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:28:16,442 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:28:39,218 INFO Kmeans.KMeansClusteringJob: im hereee
2016-01-05 06:28:39,970 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:28:39,977 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:28:40,218 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:28:40,402 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:28:40,404 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:28:40,454 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:28:40,473 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:28:40,505 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:28:41,033 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local266766851_0001
2016-01-05 06:28:41,038 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:28:41,049 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:28:41,085 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:28:41,086 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local266766851_0001_m_000000_0
2016-01-05 06:28:41,130 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:28:41,165 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:28:41,221 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 06:28:41,224 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+104
2016-01-05 06:28:41,231 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:28:41,233 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:28:41,319 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:28:41,320 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:28:41,328 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:28:41,328 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:28:41,328 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:28:41,341 INFO org.apache.hadoop.mapred.Task: Task:attempt_local266766851_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:28:41,346 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:28:41,346 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local266766851_0001_m_000000_0' done.
2016-01-05 06:28:41,346 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local266766851_0001_m_000000_0
2016-01-05 06:28:41,346 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:28:41,351 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:28:41,358 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@d24111a
2016-01-05 06:28:41,358 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:28:41,362 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:28:41,371 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-01-05 06:28:41,371 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:28:41,382 INFO org.apache.hadoop.mapred.Task: Task:attempt_local266766851_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:28:41,382 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:28:41,382 INFO org.apache.hadoop.mapred.Task: Task attempt_local266766851_0001_r_000000_0 is allowed to commit now
2016-01-05 06:28:41,384 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local266766851_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:28:41,384 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:28:41,385 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local266766851_0001_r_000000_0' done.
2016-01-05 06:28:42,036 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 100%
2016-01-05 06:28:42,037 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local266766851_0001
2016-01-05 06:28:42,042 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:28:42,043 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:28:42,043 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=1146
2016-01-05 06:28:42,043 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=179084
2016-01-05 06:28:42,044 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:28:42,044 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:28:42,044 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:28:42,044 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:28:42,044 INFO org.apache.hadoop.mapred.JobClient:     Map input records=0
2016-01-05 06:28:42,045 INFO org.apache.hadoop.mapred.JobClient:     Map output records=0
2016-01-05 06:28:42,045 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=0
2016-01-05 06:28:42,048 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 06:28:42,049 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:28:42,050 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:28:42,050 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=0
2016-01-05 06:28:42,050 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:28:42,050 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=0
2016-01-05 06:28:42,050 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=0
2016-01-05 06:28:42,050 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=0
2016-01-05 06:28:42,050 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:28:42,050 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:28:42,051 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:28:42,051 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:28:42,059 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:28:42,063 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:28:42,063 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:29:17,848 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:29:17,852 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:29:18,061 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:29:18,261 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:29:18,265 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:29:18,322 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:29:18,336 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:29:18,368 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:29:18,894 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local2092496042_0001
2016-01-05 06:29:18,898 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:29:18,911 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:29:18,945 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:29:18,948 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2092496042_0001_m_000000_0
2016-01-05 06:29:18,986 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:29:19,019 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:29:19,025 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 06:29:19,027 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 06:29:19,032 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:29:19,034 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:29:19,125 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:29:19,125 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:29:19,137 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:29:19,138 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:29:19,139 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local2092496042_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.lib.partition.HashPartitioner.getPartition(HashPartitioner.java:29)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:602)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:85)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:106)
	at Kmeans.KMeansMapper.map(KMeansMapper.java:59)
	at Kmeans.KMeansMapper.map(KMeansMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 06:29:19,897 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 06:29:19,898 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local2092496042_0001
2016-01-05 06:29:19,900 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 06:29:19,904 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:30:56,088 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:30:56,098 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:30:56,325 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:30:56,506 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:30:56,510 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:30:56,560 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:30:56,571 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:30:56,612 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:30:57,269 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1533279673_0001
2016-01-05 06:30:57,272 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:30:57,281 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:30:57,319 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:30:57,320 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1533279673_0001_m_000000_0
2016-01-05 06:30:57,418 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:30:57,529 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:30:57,548 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 06:30:57,550 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 06:30:57,556 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:30:57,558 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:30:57,648 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:30:57,648 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:30:57,663 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:30:57,664 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:30:57,666 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1533279673_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:404)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.lib.partition.HashPartitioner.getPartition(HashPartitioner.java:29)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:602)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:85)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:106)
	at Kmeans.KMeansMapper.map(KMeansMapper.java:59)
	at Kmeans.KMeansMapper.map(KMeansMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:673)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
2016-01-05 06:30:58,271 INFO org.apache.hadoop.mapred.JobClient:  map 0% reduce 0%
2016-01-05 06:30:58,272 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1533279673_0001
2016-01-05 06:30:58,273 INFO org.apache.hadoop.mapred.JobClient: Counters: 0
2016-01-05 06:30:58,277 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:31:36,681 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:31:36,688 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:31:36,898 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:31:37,083 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:31:37,091 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:31:37,129 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:31:37,143 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:31:37,187 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:31:37,895 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1460053698_0001
2016-01-05 06:31:37,901 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:31:37,910 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:31:37,964 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:31:37,966 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1460053698_0001_m_000000_0
2016-01-05 06:31:38,037 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:31:38,092 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:31:38,096 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 06:31:38,099 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 06:31:38,104 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:31:38,106 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:31:38,194 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:31:38,194 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:31:38,204 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:31:38,265 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:38,266 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:31:38,274 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:31:38,280 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1460053698_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:31:38,287 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:38,288 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1460053698_0001_m_000000_0' done.
2016-01-05 06:31:38,288 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1460053698_0001_m_000000_0
2016-01-05 06:31:38,288 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:31:38,291 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:31:38,296 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5a20f443
2016-01-05 06:31:38,296 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:38,301 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:31:38,310 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:31:38,310 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:38,327 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1460053698_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:31:38,328 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:38,328 INFO org.apache.hadoop.mapred.Task: Task attempt_local1460053698_0001_r_000000_0 is allowed to commit now
2016-01-05 06:31:38,330 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1460053698_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:31:38,330 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:31:38,330 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1460053698_0001_r_000000_0' done.
2016-01-05 06:31:38,911 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:31:38,913 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1460053698_0001
2016-01-05 06:31:38,920 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 06:31:38,921 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:31:38,921 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2548
2016-01-05 06:31:38,921 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181654
2016-01-05 06:31:38,921 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:31:38,922 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:31:38,922 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:31:38,922 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:31:38,922 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:31:38,922 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:31:38,922 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:31:38,922 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 06:31:38,922 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:31:38,922 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:31:38,923 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:31:38,923 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:31:38,923 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:31:38,923 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:31:38,923 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:31:38,923 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:31:38,923 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:31:38,923 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:31:38,924 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:31:38,924 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 06:31:38,924 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 06:31:39,010 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 06:31:39,011 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:31:39,012 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:31:39,024 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:31:39,217 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local648499890_0002
2016-01-05 06:31:39,217 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:31:39,218 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:31:39,224 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:31:39,225 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local648499890_0002_m_000000_0
2016-01-05 06:31:39,225 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:31:39,232 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@7fcebc9f
2016-01-05 06:31:39,235 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_1/part-r-00000:0+493
2016-01-05 06:31:39,241 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:31:39,242 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:31:39,399 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:31:39,402 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:31:39,419 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:39,419 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:31:39,421 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:31:39,429 INFO org.apache.hadoop.mapred.Task: Task:attempt_local648499890_0002_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:31:39,432 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:39,434 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local648499890_0002_m_000000_0' done.
2016-01-05 06:31:39,434 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local648499890_0002_m_000000_0
2016-01-05 06:31:39,434 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:31:39,435 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:31:39,445 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@48e29820
2016-01-05 06:31:39,445 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:39,446 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:31:39,451 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:31:39,451 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:39,468 INFO org.apache.hadoop.mapred.Task: Task:attempt_local648499890_0002_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:31:39,474 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:39,474 INFO org.apache.hadoop.mapred.Task: Task attempt_local648499890_0002_r_000000_0 is allowed to commit now
2016-01-05 06:31:39,478 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local648499890_0002_r_000000_0' to files/clustering/depth_2
2016-01-05 06:31:39,482 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:31:39,482 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local648499890_0002_r_000000_0' done.
2016-01-05 06:31:40,218 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:31:40,218 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local648499890_0002
2016-01-05 06:31:40,220 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 06:31:40,220 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:31:40,220 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=5146
2016-01-05 06:31:40,221 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=362524
2016-01-05 06:31:40,221 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:31:40,221 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:31:40,221 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:31:40,221 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:31:40,222 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:31:40,222 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:31:40,222 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:31:40,225 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 06:31:40,226 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:31:40,228 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:31:40,228 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:31:40,229 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:31:40,230 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:31:40,230 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:31:40,231 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:31:40,231 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:31:40,231 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:31:40,232 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:31:40,234 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:31:40,235 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 06:31:40,236 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 06:31:40,307 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 06:31:40,309 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:31:40,312 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:31:40,319 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:31:40,470 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1619516989_0003
2016-01-05 06:31:40,471 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:31:40,472 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:31:40,479 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:31:40,479 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1619516989_0003_m_000000_0
2016-01-05 06:31:40,479 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:31:40,480 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@4cc5aa00
2016-01-05 06:31:40,481 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_2/part-r-00000:0+493
2016-01-05 06:31:40,482 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:31:40,483 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:31:40,566 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:31:40,567 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:31:40,584 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:40,585 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:31:40,590 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:31:40,591 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1619516989_0003_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:31:40,592 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:40,593 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1619516989_0003_m_000000_0' done.
2016-01-05 06:31:40,593 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1619516989_0003_m_000000_0
2016-01-05 06:31:40,593 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:31:40,593 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:31:40,596 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@3b926e90
2016-01-05 06:31:40,597 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:40,599 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:31:40,600 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:31:40,600 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:40,605 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1619516989_0003_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:31:40,606 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:31:40,606 INFO org.apache.hadoop.mapred.Task: Task attempt_local1619516989_0003_r_000000_0 is allowed to commit now
2016-01-05 06:31:40,612 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1619516989_0003_r_000000_0' to files/clustering/depth_3
2016-01-05 06:31:40,613 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:31:40,614 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1619516989_0003_r_000000_0' done.
2016-01-05 06:31:41,472 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:31:41,473 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1619516989_0003
2016-01-05 06:31:41,476 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:31:41,477 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:31:41,477 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=7744
2016-01-05 06:31:41,477 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=543402
2016-01-05 06:31:41,477 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:31:41,477 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:31:41,477 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:31:41,477 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:31:41,478 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:31:41,478 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:31:41,478 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:31:41,478 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 06:31:41,478 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:31:41,478 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:31:41,478 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:31:41,478 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:31:41,478 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:31:41,479 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:31:41,479 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:31:41,479 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:31:41,479 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:31:41,479 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:31:41,479 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=440270848
2016-01-05 06:31:41,481 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:31:41,482 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:31:41,482 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:34:35,955 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:34:35,957 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:34:35,987 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 06:34:35,992 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 06:34:36,169 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:34:36,469 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:34:36,470 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:34:36,653 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:34:36,666 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:34:36,683 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:34:37,298 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1600553592_0001
2016-01-05 06:34:37,307 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:34:37,314 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:34:37,323 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:34:37,323 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1600553592_0001_m_000000_0
2016-01-05 06:34:37,340 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:34:37,365 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:34:37,417 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 06:34:37,419 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/import/data:0+530
2016-01-05 06:34:37,425 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:34:37,427 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:34:37,520 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:34:37,520 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:34:37,528 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:34:37,529 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:37,530 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:34:37,540 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:34:37,545 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1600553592_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:34:37,550 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:37,550 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1600553592_0001_m_000000_0' done.
2016-01-05 06:34:37,550 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1600553592_0001_m_000000_0
2016-01-05 06:34:37,550 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:34:37,553 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:34:37,558 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5a20f443
2016-01-05 06:34:37,558 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:37,562 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:34:37,576 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:34:37,576 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:37,590 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1600553592_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:34:37,590 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:37,591 INFO org.apache.hadoop.mapred.Task: Task attempt_local1600553592_0001_r_000000_0 is allowed to commit now
2016-01-05 06:34:37,592 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1600553592_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:34:37,593 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:34:37,593 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1600553592_0001_r_000000_0' done.
2016-01-05 06:34:38,308 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:34:38,309 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1600553592_0001
2016-01-05 06:34:38,317 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 06:34:38,317 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:34:38,317 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2708
2016-01-05 06:34:38,317 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181654
2016-01-05 06:34:38,318 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:34:38,318 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:34:38,318 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:34:38,318 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:34:38,318 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:34:38,318 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:34:38,318 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:34:38,318 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=130
2016-01-05 06:34:38,318 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:34:38,319 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:34:38,319 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:34:38,319 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:34:38,319 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:34:38,319 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:34:38,319 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:34:38,319 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:34:38,319 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:34:38,320 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:34:38,320 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:34:38,320 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 06:34:38,320 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 06:34:38,393 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 06:34:38,396 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:34:38,401 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:34:38,409 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:34:38,613 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local296188988_0002
2016-01-05 06:34:38,613 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:34:38,614 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:34:38,624 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:34:38,624 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local296188988_0002_m_000000_0
2016-01-05 06:34:38,627 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:34:38,631 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@7fcebc9f
2016-01-05 06:34:38,633 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_1/part-r-00000:0+493
2016-01-05 06:34:38,639 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:34:38,639 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:34:38,755 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:34:38,756 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:34:38,778 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:38,778 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:34:38,780 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:34:38,787 INFO org.apache.hadoop.mapred.Task: Task:attempt_local296188988_0002_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:34:38,795 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:38,795 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local296188988_0002_m_000000_0' done.
2016-01-05 06:34:38,795 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local296188988_0002_m_000000_0
2016-01-05 06:34:38,797 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:34:38,798 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:34:38,807 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@3c1fc1a6
2016-01-05 06:34:38,808 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:38,809 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:34:38,809 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:34:38,809 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:38,833 INFO org.apache.hadoop.mapred.Task: Task:attempt_local296188988_0002_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:34:38,834 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:38,844 INFO org.apache.hadoop.mapred.Task: Task attempt_local296188988_0002_r_000000_0 is allowed to commit now
2016-01-05 06:34:38,850 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local296188988_0002_r_000000_0' to files/clustering/depth_2
2016-01-05 06:34:38,850 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:34:38,850 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local296188988_0002_r_000000_0' done.
2016-01-05 06:34:39,614 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:34:39,614 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local296188988_0002
2016-01-05 06:34:39,616 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 06:34:39,616 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:34:39,616 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=5306
2016-01-05 06:34:39,616 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=362524
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:34:39,617 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:34:39,618 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:34:39,618 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:34:39,618 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:34:39,618 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 06:34:39,618 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 06:34:39,644 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 06:34:39,645 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:34:39,647 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:34:39,649 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:34:39,735 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local935331487_0003
2016-01-05 06:34:39,735 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:34:39,736 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:34:39,739 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:34:39,739 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local935331487_0003_m_000000_0
2016-01-05 06:34:39,739 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:34:39,740 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@21c783c5
2016-01-05 06:34:39,741 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_2/part-r-00000:0+493
2016-01-05 06:34:39,742 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:34:39,742 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:34:39,808 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:34:39,808 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:34:39,826 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:39,830 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:34:39,831 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:34:39,835 INFO org.apache.hadoop.mapred.Task: Task:attempt_local935331487_0003_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:34:39,841 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:39,841 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local935331487_0003_m_000000_0' done.
2016-01-05 06:34:39,842 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local935331487_0003_m_000000_0
2016-01-05 06:34:39,842 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:34:39,842 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:34:39,856 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@30b3f9b8
2016-01-05 06:34:39,857 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:39,858 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:34:39,860 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:34:39,860 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:39,865 INFO org.apache.hadoop.mapred.Task: Task:attempt_local935331487_0003_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:34:39,866 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:34:39,866 INFO org.apache.hadoop.mapred.Task: Task attempt_local935331487_0003_r_000000_0 is allowed to commit now
2016-01-05 06:34:39,868 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local935331487_0003_r_000000_0' to files/clustering/depth_3
2016-01-05 06:34:39,868 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:34:39,868 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local935331487_0003_r_000000_0' done.
2016-01-05 06:34:40,736 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:34:40,736 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local935331487_0003
2016-01-05 06:34:40,738 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:34:40,739 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:34:40,739 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=7904
2016-01-05 06:34:40,739 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=543394
2016-01-05 06:34:40,739 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:34:40,739 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:34:40,739 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:34:40,740 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:34:40,740 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:34:40,740 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:34:40,740 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:34:40,740 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 06:34:40,740 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:34:40,740 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:34:40,740 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:34:40,740 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:34:40,741 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:34:40,741 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:34:40,741 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:34:40,741 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:34:40,741 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:34:40,741 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:34:40,741 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=440270848
2016-01-05 06:34:40,744 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:34:40,744 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:34:40,745 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:39:04,518 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:39:04,526 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:39:04,573 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 06:39:04,573 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 06:39:04,758 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:39:04,949 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:39:04,950 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:39:05,005 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:39:05,020 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:39:05,053 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:39:05,785 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:39:05,801 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local104341637_0001
2016-01-05 06:39:05,809 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:39:05,858 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:39:05,859 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local104341637_0001_m_000000_0
2016-01-05 06:39:05,945 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:39:06,045 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:39:06,059 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 06:39:06,062 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+530
2016-01-05 06:39:06,075 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:39:06,081 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:39:06,226 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:39:06,227 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:39:06,245 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:39:06,247 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:06,249 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:39:06,269 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:39:06,276 INFO org.apache.hadoop.mapred.Task: Task:attempt_local104341637_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:39:06,289 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:06,289 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local104341637_0001_m_000000_0' done.
2016-01-05 06:39:06,289 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local104341637_0001_m_000000_0
2016-01-05 06:39:06,290 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:39:06,297 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:39:06,309 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5a20f443
2016-01-05 06:39:06,309 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:06,314 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:39:06,349 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:39:06,349 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:06,430 INFO org.apache.hadoop.mapred.Task: Task:attempt_local104341637_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:39:06,431 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:06,434 INFO org.apache.hadoop.mapred.Task: Task attempt_local104341637_0001_r_000000_0 is allowed to commit now
2016-01-05 06:39:06,437 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local104341637_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:39:06,441 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:39:06,441 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local104341637_0001_r_000000_0' done.
2016-01-05 06:39:06,811 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:39:06,812 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local104341637_0001
2016-01-05 06:39:06,820 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 06:39:06,820 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:39:06,821 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2686
2016-01-05 06:39:06,821 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181580
2016-01-05 06:39:06,821 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:39:06,821 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:39:06,821 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:39:06,821 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:39:06,821 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:39:06,821 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:39:06,821 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:39:06,822 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 06:39:06,822 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:39:06,822 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:39:06,822 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:39:06,822 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:39:06,822 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:39:06,822 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:39:06,822 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:39:06,822 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:39:06,822 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:39:06,823 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:39:06,823 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:39:06,823 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 06:39:06,823 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 06:39:06,908 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 06:39:06,909 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:39:06,911 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:39:06,929 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:39:07,142 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1964178007_0002
2016-01-05 06:39:07,143 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:39:07,144 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:39:07,150 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:39:07,151 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1964178007_0002_m_000000_0
2016-01-05 06:39:07,151 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:39:07,158 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@77546dbc
2016-01-05 06:39:07,159 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_1/part-r-00000:0+493
2016-01-05 06:39:07,159 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:39:07,160 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:39:07,272 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:39:07,273 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:39:07,287 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:07,290 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:39:07,299 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:39:07,306 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1964178007_0002_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:39:07,308 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:07,312 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1964178007_0002_m_000000_0' done.
2016-01-05 06:39:07,317 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1964178007_0002_m_000000_0
2016-01-05 06:39:07,319 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:39:07,319 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:39:07,323 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@344977e2
2016-01-05 06:39:07,323 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:07,324 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:39:07,330 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:39:07,330 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:07,357 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1964178007_0002_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:39:07,358 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:07,358 INFO org.apache.hadoop.mapred.Task: Task attempt_local1964178007_0002_r_000000_0 is allowed to commit now
2016-01-05 06:39:07,360 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1964178007_0002_r_000000_0' to files/clustering/depth_2
2016-01-05 06:39:07,361 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:39:07,361 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1964178007_0002_r_000000_0' done.
2016-01-05 06:39:08,144 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:39:08,144 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1964178007_0002
2016-01-05 06:39:08,146 INFO org.apache.hadoop.mapred.JobClient: Counters: 21
2016-01-05 06:39:08,146 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:39:08,146 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=5284
2016-01-05 06:39:08,146 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=362458
2016-01-05 06:39:08,146 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:39:08,146 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:39:08,146 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:39:08,146 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:39:08,146 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:39:08,146 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:39:08,146 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:39:08,146 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 06:39:08,147 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:39:08,147 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:39:08,147 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:39:08,147 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:39:08,147 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:39:08,148 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:39:08,149 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:39:08,149 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:39:08,149 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:39:08,149 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:39:08,149 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:39:08,149 INFO org.apache.hadoop.mapred.JobClient:   Kmeans.KMeansReducer$Counter
2016-01-05 06:39:08,149 INFO org.apache.hadoop.mapred.JobClient:     CONVERGED=2
2016-01-05 06:39:08,179 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
2016-01-05 06:39:08,180 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:39:08,181 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:39:08,183 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:39:08,275 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1790120186_0003
2016-01-05 06:39:08,278 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:39:08,280 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:39:08,290 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:39:08,290 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1790120186_0003_m_000000_0
2016-01-05 06:39:08,290 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:39:08,296 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@609903f4
2016-01-05 06:39:08,297 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/workspace/Canopy/files/clustering/depth_2/part-r-00000:0+493
2016-01-05 06:39:08,297 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:39:08,298 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:39:08,369 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:39:08,369 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:39:08,386 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:08,386 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:39:08,388 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:39:08,389 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1790120186_0003_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:39:08,391 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:08,391 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1790120186_0003_m_000000_0' done.
2016-01-05 06:39:08,391 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1790120186_0003_m_000000_0
2016-01-05 06:39:08,391 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:39:08,392 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:39:08,397 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5f7779e3
2016-01-05 06:39:08,398 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:08,398 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:39:08,399 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:39:08,399 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:08,405 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1790120186_0003_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:39:08,406 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:08,406 INFO org.apache.hadoop.mapred.Task: Task attempt_local1790120186_0003_r_000000_0 is allowed to commit now
2016-01-05 06:39:08,407 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1790120186_0003_r_000000_0' to files/clustering/depth_3
2016-01-05 06:39:08,408 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:39:08,408 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1790120186_0003_r_000000_0' done.
2016-01-05 06:39:09,277 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:39:09,277 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1790120186_0003
2016-01-05 06:39:09,278 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:39:09,278 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:39:09,278 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=7882
2016-01-05 06:39:09,278 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=543336
2016-01-05 06:39:09,278 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:39:09,278 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:39:09,279 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:39:09,279 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:39:09,279 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:39:09,279 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:39:09,279 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:39:09,279 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=139
2016-01-05 06:39:09,279 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:39:09,280 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:39:09,280 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:39:09,280 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:39:09,280 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:39:09,280 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:39:09,280 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:39:09,280 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:39:09,280 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:39:09,280 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:39:09,280 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=440270848
2016-01-05 06:39:09,283 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:39:09,284 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:39:09,284 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:39:25,634 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:39:25,641 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:39:25,687 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 06:39:25,694 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 06:39:25,896 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:39:26,090 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:39:26,093 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:39:26,140 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:39:26,150 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:39:26,179 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:39:26,931 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1956040695_0001
2016-01-05 06:39:26,940 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:39:26,961 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:39:27,016 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:39:27,017 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1956040695_0001_m_000000_0
2016-01-05 06:39:27,072 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:39:27,127 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:39:27,131 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@26a3960
2016-01-05 06:39:27,133 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+530
2016-01-05 06:39:27,140 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:39:27,142 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:39:27,231 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:39:27,232 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:39:27,240 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:39:27,242 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:27,242 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:39:27,255 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:39:27,257 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1956040695_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:39:27,262 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:27,263 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1956040695_0001_m_000000_0' done.
2016-01-05 06:39:27,263 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1956040695_0001_m_000000_0
2016-01-05 06:39:27,263 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:39:27,267 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:39:27,275 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5a20f443
2016-01-05 06:39:27,275 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:27,279 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:39:27,289 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:39:27,289 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:27,305 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1956040695_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:39:27,306 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:27,306 INFO org.apache.hadoop.mapred.Task: Task attempt_local1956040695_0001_r_000000_0 is allowed to commit now
2016-01-05 06:39:27,307 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1956040695_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:39:27,308 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:39:27,308 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1956040695_0001_r_000000_0' done.
2016-01-05 06:39:27,933 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:39:27,935 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1956040695_0001
2016-01-05 06:39:27,939 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:39:27,940 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:39:27,940 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2686
2016-01-05 06:39:27,940 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=181158
2016-01-05 06:39:27,940 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:39:27,940 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:39:27,940 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:39:27,940 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:39:27,940 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:39:27,941 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:39:27,941 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:39:27,941 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 06:39:27,941 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:39:27,941 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:39:27,941 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:39:27,944 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:39:27,944 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:39:27,944 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:39:27,945 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:39:27,945 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:39:27,945 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:39:27,945 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:39:27,945 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:39:27,952 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:39:27,953 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:39:27,953 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:39:41,124 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:39:41,133 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:39:41,174 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 06:39:41,175 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 06:39:41,405 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:39:41,411 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:39:41,549 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:39:41,570 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:39:41,597 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:39:42,195 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local1449408752_0001
2016-01-05 06:39:42,195 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:39:42,212 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:39:42,239 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:39:42,243 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1449408752_0001_m_000000_0
2016-01-05 06:39:42,305 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:39:42,461 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:39:42,490 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5815338
2016-01-05 06:39:42,492 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+530
2016-01-05 06:39:42,528 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:39:42,538 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:39:42,642 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:39:42,642 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:39:42,650 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:39:42,652 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:42,652 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:39:42,663 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:39:42,665 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1449408752_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:39:42,670 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:42,671 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1449408752_0001_m_000000_0' done.
2016-01-05 06:39:42,671 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1449408752_0001_m_000000_0
2016-01-05 06:39:42,671 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:39:42,674 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:39:42,681 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5470be88
2016-01-05 06:39:42,682 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:42,686 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:39:42,696 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:39:42,696 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:42,748 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:39:42,751 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1449408752_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:39:42,752 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:39:42,752 INFO org.apache.hadoop.mapred.Task: Task attempt_local1449408752_0001_r_000000_0 is allowed to commit now
2016-01-05 06:39:42,754 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1449408752_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:39:42,754 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:39:42,755 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1449408752_0001_r_000000_0' done.
2016-01-05 06:39:43,208 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:39:43,209 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local1449408752_0001
2016-01-05 06:39:43,213 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:39:43,213 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:39:43,213 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2686
2016-01-05 06:39:43,214 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=180066
2016-01-05 06:39:43,214 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:39:43,214 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:39:43,214 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:39:43,214 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:39:43,214 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:39:43,214 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:39:43,214 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:39:43,215 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 06:39:43,215 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:39:43,215 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:39:43,215 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:39:43,215 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:39:43,218 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:39:43,218 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:39:43,219 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:39:43,219 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:39:43,219 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:39:43,219 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:39:43,219 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:39:43,226 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:39:43,227 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:39:43,227 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:40:03,074 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:40:03,081 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:40:03,121 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 06:40:03,124 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 06:40:03,361 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:40:03,364 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:40:03,509 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:40:03,528 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:40:03,561 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:40:04,210 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local577968660_0001
2016-01-05 06:40:04,212 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:40:04,229 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:40:04,287 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:40:04,291 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local577968660_0001_m_000000_0
2016-01-05 06:40:04,356 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:40:04,497 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:40:04,528 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@6d7e845a
2016-01-05 06:40:04,531 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+530
2016-01-05 06:40:04,555 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:40:04,571 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:40:04,720 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:40:04,720 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:40:04,727 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:40:04,730 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:40:04,730 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:40:04,739 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:40:04,740 INFO org.apache.hadoop.mapred.Task: Task:attempt_local577968660_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:40:04,745 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:40:04,746 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local577968660_0001_m_000000_0' done.
2016-01-05 06:40:04,746 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local577968660_0001_m_000000_0
2016-01-05 06:40:04,746 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:40:04,750 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:40:04,758 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5470be88
2016-01-05 06:40:04,758 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:40:04,763 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:40:04,782 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:40:04,782 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:40:04,820 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:40:04,821 INFO org.apache.hadoop.mapred.Task: Task:attempt_local577968660_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:40:04,822 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:40:04,822 INFO org.apache.hadoop.mapred.Task: Task attempt_local577968660_0001_r_000000_0 is allowed to commit now
2016-01-05 06:40:04,824 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local577968660_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:40:04,824 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:40:04,825 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local577968660_0001_r_000000_0' done.
2016-01-05 06:40:05,224 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:40:05,225 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local577968660_0001
2016-01-05 06:40:05,230 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:40:05,230 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:40:05,230 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2686
2016-01-05 06:40:05,230 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=180058
2016-01-05 06:40:05,230 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:40:05,230 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:40:05,230 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:40:05,230 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:40:05,230 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:40:05,231 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:40:05,233 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:40:05,234 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 06:40:05,234 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:40:05,234 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:40:05,234 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:40:05,235 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:40:05,235 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:40:05,235 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:40:05,235 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:40:05,235 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:40:05,235 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:40:05,235 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:40:05,235 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:40:05,245 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:40:05,246 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:40:05,246 INFO Kmeans.KMeansClusteringJob: SHAY2
2016-01-05 06:41:27,244 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2016-01-05 06:41:27,248 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:41:27,290 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[1.4, -2.6]]] / 0
2016-01-05 06:41:27,290 INFO Kmeans.KMeansClusteringJob: ClusterCenter [center=Vector [vector=[13.5, 3.75]]] / 0
2016-01-05 06:41:27,517 WARN org.apache.hadoop.conf.Configuration: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-01-05 06:41:27,528 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-01-05 06:41:27,712 WARN org.apache.hadoop.mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
2016-01-05 06:41:27,736 WARN org.apache.hadoop.mapred.JobClient: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
2016-01-05 06:41:27,760 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-01-05 06:41:28,287 INFO org.apache.hadoop.mapred.JobClient: Running job: job_local132744366_0001
2016-01-05 06:41:28,288 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-01-05 06:41:28,296 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-01-05 06:41:28,331 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-01-05 06:41:28,335 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local132744366_0001_m_000000_0
2016-01-05 06:41:28,387 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:41:28,471 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2016-01-05 06:41:28,527 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@6d7e845a
2016-01-05 06:41:28,529 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/training/Desktop/Kmeans/input/CanopyVectors:0+530
2016-01-05 06:41:28,536 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-01-05 06:41:28,538 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 100
2016-01-05 06:41:28,627 INFO org.apache.hadoop.mapred.MapTask: data buffer = 79691776/99614720
2016-01-05 06:41:28,627 INFO org.apache.hadoop.mapred.MapTask: record buffer = 262144/327680
2016-01-05 06:41:28,637 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2016-01-05 06:41:28,642 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:41:28,643 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-01-05 06:41:28,659 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-01-05 06:41:28,662 INFO org.apache.hadoop.mapred.Task: Task:attempt_local132744366_0001_m_000000_0 is done. And is in the process of commiting
2016-01-05 06:41:28,669 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:41:28,669 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local132744366_0001_m_000000_0' done.
2016-01-05 06:41:28,669 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local132744366_0001_m_000000_0
2016-01-05 06:41:28,669 INFO org.apache.hadoop.mapred.LocalJobRunner: Map task executor complete.
2016-01-05 06:41:28,673 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2016-01-05 06:41:28,688 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@5470be88
2016-01-05 06:41:28,688 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:41:28,693 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-01-05 06:41:28,707 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 380 bytes
2016-01-05 06:41:28,707 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:41:28,760 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2016-01-05 06:41:28,766 INFO org.apache.hadoop.mapred.Task: Task:attempt_local132744366_0001_r_000000_0 is done. And is in the process of commiting
2016-01-05 06:41:28,766 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-01-05 06:41:28,769 INFO org.apache.hadoop.mapred.Task: Task attempt_local132744366_0001_r_000000_0 is allowed to commit now
2016-01-05 06:41:28,771 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local132744366_0001_r_000000_0' to files/clustering/depth_1
2016-01-05 06:41:28,775 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-01-05 06:41:28,776 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local132744366_0001_r_000000_0' done.
2016-01-05 06:41:29,293 INFO org.apache.hadoop.mapred.JobClient:  map 100% reduce 100%
2016-01-05 06:41:29,294 INFO org.apache.hadoop.mapred.JobClient: Job complete: job_local132744366_0001
2016-01-05 06:41:29,304 INFO org.apache.hadoop.mapred.JobClient: Counters: 20
2016-01-05 06:41:29,304 INFO org.apache.hadoop.mapred.JobClient:   File System Counters
2016-01-05 06:41:29,304 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes read=2686
2016-01-05 06:41:29,304 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of bytes written=180058
2016-01-05 06:41:29,305 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of read operations=0
2016-01-05 06:41:29,305 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of large read operations=0
2016-01-05 06:41:29,305 INFO org.apache.hadoop.mapred.JobClient:     FILE: Number of write operations=0
2016-01-05 06:41:29,305 INFO org.apache.hadoop.mapred.JobClient:   Map-Reduce Framework
2016-01-05 06:41:29,306 INFO org.apache.hadoop.mapred.JobClient:     Map input records=9
2016-01-05 06:41:29,309 INFO org.apache.hadoop.mapred.JobClient:     Map output records=9
2016-01-05 06:41:29,313 INFO org.apache.hadoop.mapred.JobClient:     Map output bytes=360
2016-01-05 06:41:29,313 INFO org.apache.hadoop.mapred.JobClient:     Input split bytes=119
2016-01-05 06:41:29,313 INFO org.apache.hadoop.mapred.JobClient:     Combine input records=0
2016-01-05 06:41:29,313 INFO org.apache.hadoop.mapred.JobClient:     Combine output records=0
2016-01-05 06:41:29,313 INFO org.apache.hadoop.mapred.JobClient:     Reduce input groups=2
2016-01-05 06:41:29,313 INFO org.apache.hadoop.mapred.JobClient:     Reduce shuffle bytes=0
2016-01-05 06:41:29,317 INFO org.apache.hadoop.mapred.JobClient:     Reduce input records=9
2016-01-05 06:41:29,317 INFO org.apache.hadoop.mapred.JobClient:     Reduce output records=9
2016-01-05 06:41:29,317 INFO org.apache.hadoop.mapred.JobClient:     Spilled Records=18
2016-01-05 06:41:29,317 INFO org.apache.hadoop.mapred.JobClient:     CPU time spent (ms)=0
2016-01-05 06:41:29,318 INFO org.apache.hadoop.mapred.JobClient:     Physical memory (bytes) snapshot=0
2016-01-05 06:41:29,318 INFO org.apache.hadoop.mapred.JobClient:     Virtual memory (bytes) snapshot=0
2016-01-05 06:41:29,318 INFO org.apache.hadoop.mapred.JobClient:     Total committed heap usage (bytes)=320741376
2016-01-05 06:41:29,329 INFO Kmeans.KMeansClusteringJob: SHAY0
2016-01-05 06:41:29,330 INFO Kmeans.KMeansClusteringJob: SHAY1
2016-01-05 06:41:29,333 INFO Kmeans.KMeansClusteringJob: SHAY2
